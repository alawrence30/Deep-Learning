{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/alawrence30/Deep-Learning/blob/main/B_MSDS458_Assignment_03_EDA_v1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xHJ-2a8LRro5"
      },
      "source": [
        "<img src=\"https://github.com/djp840/MSDS_458_Public/blob/master/images/NorthwesternHeader.png?raw=1\">"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k6cApW345ukg"
      },
      "source": [
        "## Experiments B: RNN\n",
        "\n",
        "Try several experiments by tweaking \n",
        "\n",
        "(i) architecture \n",
        "\n",
        "(ii) Bidirectional/unidirectional & other hyper parameters, including regularization."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ydgzc1l15ukl"
      },
      "source": [
        "## Functions and Packages"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "9d9VZa_T5ukm"
      },
      "outputs": [],
      "source": [
        "from packaging import version\n",
        "import numpy as np\n",
        "import re\n",
        "import string\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "import tensorflow_datasets as tfds\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "\n",
        "import nltk\n",
        "from nltk.corpus import stopwords"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SNt8VbLK5ukp"
      },
      "source": [
        "### Verify TensorFlow version and Keras version"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kujC9adr5ukq",
        "outputId": "4746096e-d84a-457a-e50b-0d4b040f86cb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "This notebook requires TensorFlow 2.0 or above\n",
            "TensorFlow version:  2.9.2\n"
          ]
        }
      ],
      "source": [
        "print(\"This notebook requires TensorFlow 2.0 or above\")\n",
        "print(\"TensorFlow version: \", tf.__version__)\n",
        "assert version.parse(tf.__version__).release[0] >=2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UHdPTZRp5ukr",
        "outputId": "67c1499c-3cc3-4cc2-cd48-459b367532ba"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Keras version:  2.9.0\n"
          ]
        }
      ],
      "source": [
        "print(\"Keras version: \", keras.__version__)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AHfRyGdPxref"
      },
      "source": [
        "### Stopword Function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "syHVsHBfxref"
      },
      "outputs": [],
      "source": [
        "def custom_stopwords(input_text):\n",
        "    lowercase = tf.strings.lower(input_text)\n",
        "    stripped_punct = tf.strings.regex_replace(lowercase\n",
        "                                  ,'[%s]' % re.escape(string.punctuation)\n",
        "                                  ,'')\n",
        "    return tf.strings.regex_replace(stripped_punct, r'\\b(' + r'|'.join(STOPWORDS) + r')\\b\\s*',\"\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z1Gn6wYG5uks"
      },
      "source": [
        "## Mount Google Drive to Colab environment"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "8jHzLMMB5ukt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fe329774-8c5d-4374-dbad-aeb846776bd5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ],
      "source": [
        "#from google.colab import drive\n",
        "#drive.mount('/content/gdrive')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XvqFLia1Rro9"
      },
      "source": [
        "## Load Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EsypDzDARro-",
        "outputId": "c9f5cf7e-32e8-4466-bc6a-23a104a92c5a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "W1104 16:45:16.530793 139684261742464 download_and_prepare.py:43] ***`tfds build` should be used instead of `download_and_prepare`.***\n",
            "INFO[build.py]: Loading dataset ag_news_subset from imports: tensorflow_datasets.text.ag_news_subset\n",
            "2022-11-04 16:45:17.170720: W tensorflow/core/platform/cloud/google_auth_provider.cc:184] All attempts to get a Google authentication bearer token failed, returning an empty token. Retrieving token from files failed with \"NOT_FOUND: Could not locate the credentials file.\". Retrieving token from GCE failed with \"NOT_FOUND: Error executing an HTTP request: HTTP response code 404\".\n",
            "INFO[dataset_info.py]: Load pre-computed DatasetInfo (eg: splits, num examples,...) from GCS: ag_news_subset/1.0.0\n",
            "INFO[dataset_info.py]: Load dataset info from /tmp/tmpuousx6kotfds\n",
            "INFO[dataset_info.py]: Field info.splits from disk and from code do not match. Keeping the one from code.\n",
            "INFO[dataset_info.py]: Field info.supervised_keys from disk and from code do not match. Keeping the one from code.\n",
            "INFO[dataset_info.py]: Field info.module_name from disk and from code do not match. Keeping the one from code.\n",
            "INFO[build.py]: download_and_prepare for dataset ag_news_subset/1.0.0...\n",
            "INFO[dataset_builder.py]: Generating dataset ag_news_subset (/root/tensorflow_datasets/ag_news_subset/1.0.0)\n",
            "\u001b[1mDownloading and preparing dataset 11.24 MiB (download: 11.24 MiB, generated: 35.79 MiB, total: 47.03 MiB) to /root/tensorflow_datasets/ag_news_subset/1.0.0...\u001b[0m\n",
            "Dl Completed...: 0 url [00:00, ? url/s]\n",
            "Dl Size...: 0 MiB [00:00, ? MiB/s]\u001b[A\n",
            "\n",
            "                                       \n",
            "\n",
            "\u001b[A\u001b[A\n",
            "\u001b[AINFO[download_manager.py]: Downloading https://drive.google.com/uc?export=download&id=0Bz8a_Dbh9QhbUDNpeUdjb0wxRms into /root/tensorflow_datasets/downloads/ucexport_download_id_0Bz8a_Dbh9QhbUDNpeUdjb0wxj4g1umFAV8OV-uDwxSJR0LdxO_k1jxMuFWwAfNX9jos.tmp.a108098f937048e8bc05152a374ab6bd...\n",
            "Dl Completed...: 0 url [00:00, ? url/s]\n",
            "\n",
            "Extraction completed...: 0 file [00:00, ? file/s]\u001b[A\u001b[A\n",
            "Dl Completed...:   0% 0/1 [00:00<?, ? url/s]\n",
            "Dl Size...: 0 MiB [00:00, ? MiB/s]\u001b[A\n",
            "\n",
            "Dl Completed...:   0% 0/1 [00:09<?, ? url/s]\n",
            "Dl Size...:   0% 0/11 [00:09<?, ? MiB/s]\u001b[A\n",
            "\n",
            "Extraction completed...: 0 file [00:09, ? file/s]\u001b[A\u001b[A\n",
            "Dl Completed...:   0% 0/1 [00:09<?, ? url/s]\n",
            "Dl Size...:   9% 1/11 [00:09<01:39,  9.98s/ MiB]\u001b[A\n",
            "\n",
            "Dl Completed...:   0% 0/1 [00:09<?, ? url/s]\n",
            "Dl Size...:  18% 2/11 [00:09<01:29,  9.98s/ MiB]\u001b[A\n",
            "\n",
            "Dl Completed...:   0% 0/1 [00:10<?, ? url/s]\n",
            "Dl Size...:  27% 3/11 [00:10<01:19,  9.98s/ MiB]\u001b[A\n",
            "\n",
            "Dl Completed...:   0% 0/1 [00:10<?, ? url/s]\n",
            "Dl Size...:  36% 4/11 [00:10<01:09,  9.98s/ MiB]\u001b[A\n",
            "\n",
            "Dl Completed...:   0% 0/1 [00:10<?, ? url/s]\n",
            "Dl Size...:  45% 5/11 [00:10<00:59,  9.98s/ MiB]\u001b[A\n",
            "\n",
            "Dl Completed...:   0% 0/1 [00:10<?, ? url/s]\n",
            "Dl Size...:  55% 6/11 [00:10<00:49,  9.98s/ MiB]\u001b[A\n",
            "\n",
            "Dl Completed...:   0% 0/1 [00:10<?, ? url/s]\n",
            "Dl Size...:  64% 7/11 [00:10<00:39,  9.98s/ MiB]\u001b[A\n",
            "\n",
            "Extraction completed...: 0 file [00:10, ? file/s]\u001b[A\u001b[A\n",
            "Dl Completed...:   0% 0/1 [00:10<?, ? url/s]\n",
            "Dl Size...:  73% 8/11 [00:10<00:02,  1.09 MiB/s]\u001b[A\n",
            "\n",
            "Dl Completed...:   0% 0/1 [00:10<?, ? url/s]\n",
            "Dl Size...:  82% 9/11 [00:10<00:01,  1.09 MiB/s]\u001b[A\n",
            "\n",
            "Dl Completed...:   0% 0/1 [00:10<?, ? url/s]\n",
            "Dl Size...:  91% 10/11 [00:10<00:00,  1.09 MiB/s]\u001b[A\n",
            "\n",
            "Dl Completed...:   0% 0/1 [00:10<?, ? url/s]\n",
            "Dl Size...: 100% 11/11 [00:10<00:00,  1.09 MiB/s]\u001b[A\n",
            "\n",
            "Dl Completed...: 100% 1/1 [00:10<00:00, 10.13s/ url]\n",
            "Dl Size...: 100% 11/11 [00:10<00:00,  1.09 MiB/s]\u001b[A\n",
            "\n",
            "Dl Completed...: 100% 1/1 [00:10<00:00, 10.13s/ url]\n",
            "Dl Size...: 100% 11/11 [00:10<00:00,  1.09 MiB/s]\u001b[A\n",
            "\n",
            "Extraction completed...:   0% 0/1 [00:10<?, ? file/s]\u001b[A\u001b[A\n",
            "\n",
            "Dl Completed...: 100% 1/1 [00:10<00:00, 10.13s/ url]\n",
            "Dl Size...: 100% 11/11 [00:10<00:00,  1.09 MiB/s]\u001b[A\n",
            "\n",
            "Extraction completed...: 100% 1/1 [00:10<00:00, 10.56s/ file]\n",
            "Dl Size...: 100% 11/11 [00:10<00:00,  1.04 MiB/s]\n",
            "Dl Completed...: 100% 1/1 [00:10<00:00, 10.56s/ url]\n",
            "Generating splits...:   0% 0/2 [00:00<?, ? splits/s]\n",
            "Generating train examples...:   0% 0/120000 [00:00<?, ? examples/s]\u001b[A\n",
            "Generating train examples...:   1% 602/120000 [00:00<00:19, 6012.57 examples/s]\u001b[A\n",
            "Generating train examples...:   1% 1204/120000 [00:00<00:19, 6014.96 examples/s]\u001b[A\n",
            "Generating train examples...:   2% 1811/120000 [00:00<00:19, 6037.99 examples/s]\u001b[A\n",
            "Generating train examples...:   2% 2813/120000 [00:00<00:15, 7607.93 examples/s]\u001b[A\n",
            "Generating train examples...:   3% 3798/120000 [00:00<00:13, 8415.26 examples/s]\u001b[A\n",
            "Generating train examples...:   4% 4857/120000 [00:00<00:12, 9153.98 examples/s]\u001b[A\n",
            "Generating train examples...:   5% 5888/120000 [00:00<00:11, 9529.53 examples/s]\u001b[A\n",
            "Generating train examples...:   6% 6865/120000 [00:00<00:11, 9605.00 examples/s]\u001b[A\n",
            "Generating train examples...:   7% 7896/120000 [00:00<00:11, 9821.73 examples/s]\u001b[A\n",
            "Generating train examples...:   7% 8908/120000 [00:01<00:11, 9911.79 examples/s]\u001b[A\n",
            "Generating train examples...:   8% 9965/120000 [00:01<00:10, 10111.03 examples/s]\u001b[A\n",
            "Generating train examples...:   9% 10977/120000 [00:01<00:10, 10085.62 examples/s]\u001b[A\n",
            "Generating train examples...:  10% 11989/120000 [00:01<00:10, 10095.84 examples/s]\u001b[A\n",
            "Generating train examples...:  11% 13027/120000 [00:01<00:10, 10179.11 examples/s]\u001b[A\n",
            "Generating train examples...:  12% 14058/120000 [00:01<00:10, 10217.13 examples/s]\u001b[A\n",
            "Generating train examples...:  13% 15105/120000 [00:01<00:10, 10291.21 examples/s]\u001b[A\n",
            "Generating train examples...:  13% 16137/120000 [00:01<00:10, 10297.17 examples/s]\u001b[A\n",
            "Generating train examples...:  14% 17167/120000 [00:01<00:10, 10093.49 examples/s]\u001b[A\n",
            "Generating train examples...:  15% 18178/120000 [00:01<00:10, 9960.44 examples/s] \u001b[A\n",
            "Generating train examples...:  16% 19249/120000 [00:02<00:09, 10180.06 examples/s]\u001b[A\n",
            "Generating train examples...:  17% 20300/120000 [00:02<00:09, 10277.48 examples/s]\u001b[A\n",
            "Generating train examples...:  18% 21355/120000 [00:02<00:09, 10353.78 examples/s]\u001b[A\n",
            "Generating train examples...:  19% 22392/120000 [00:02<00:09, 10224.99 examples/s]\u001b[A\n",
            "Generating train examples...:  20% 23428/120000 [00:02<00:09, 10263.57 examples/s]\u001b[A\n",
            "Generating train examples...:  20% 24456/120000 [00:02<00:09, 10263.02 examples/s]\u001b[A\n",
            "Generating train examples...:  21% 25523/120000 [00:02<00:09, 10383.14 examples/s]\u001b[A\n",
            "Generating train examples...:  22% 26616/120000 [00:02<00:08, 10543.76 examples/s]\u001b[A\n",
            "Generating train examples...:  23% 27671/120000 [00:02<00:09, 10243.67 examples/s]\u001b[A\n",
            "Generating train examples...:  24% 28753/120000 [00:02<00:08, 10411.52 examples/s]\u001b[A\n",
            "Generating train examples...:  25% 29796/120000 [00:03<00:08, 10402.92 examples/s]\u001b[A\n",
            "Generating train examples...:  26% 30838/120000 [00:03<00:08, 10235.38 examples/s]\u001b[A\n",
            "Generating train examples...:  27% 31884/120000 [00:03<00:08, 10299.01 examples/s]\u001b[A\n",
            "Generating train examples...:  27% 32942/120000 [00:03<00:08, 10379.61 examples/s]\u001b[A\n",
            "Generating train examples...:  28% 33981/120000 [00:03<00:08, 10282.85 examples/s]\u001b[A\n",
            "Generating train examples...:  29% 35018/120000 [00:03<00:08, 10306.03 examples/s]\u001b[A\n",
            "Generating train examples...:  30% 36090/120000 [00:03<00:08, 10426.80 examples/s]\u001b[A\n",
            "Generating train examples...:  31% 37134/120000 [00:03<00:08, 10150.89 examples/s]\u001b[A\n",
            "Generating train examples...:  32% 38151/120000 [00:03<00:08, 9972.34 examples/s] \u001b[A\n",
            "Generating train examples...:  33% 39201/120000 [00:03<00:07, 10125.29 examples/s]\u001b[A\n",
            "Generating train examples...:  34% 40246/120000 [00:04<00:07, 10218.25 examples/s]\u001b[A\n",
            "Generating train examples...:  34% 41334/120000 [00:04<00:07, 10413.23 examples/s]\u001b[A\n",
            "Generating train examples...:  35% 42398/120000 [00:04<00:07, 10478.82 examples/s]\u001b[A\n",
            "Generating train examples...:  36% 43447/120000 [00:04<00:07, 10439.21 examples/s]\u001b[A\n",
            "Generating train examples...:  37% 44492/120000 [00:04<00:07, 10362.18 examples/s]\u001b[A\n",
            "Generating train examples...:  38% 45530/120000 [00:04<00:07, 10367.19 examples/s]\u001b[A\n",
            "Generating train examples...:  39% 46589/120000 [00:04<00:07, 10431.44 examples/s]\u001b[A\n",
            "Generating train examples...:  40% 47662/120000 [00:04<00:06, 10518.32 examples/s]\u001b[A\n",
            "Generating train examples...:  41% 48715/120000 [00:04<00:07, 9798.88 examples/s] \u001b[A\n",
            "Generating train examples...:  41% 49729/120000 [00:04<00:07, 9895.34 examples/s]\u001b[A\n",
            "Generating train examples...:  42% 50806/120000 [00:05<00:06, 10147.47 examples/s]\u001b[A\n",
            "Generating train examples...:  43% 51862/120000 [00:05<00:06, 10266.19 examples/s]\u001b[A\n",
            "Generating train examples...:  44% 52905/120000 [00:05<00:06, 10312.06 examples/s]\u001b[A\n",
            "Generating train examples...:  45% 53940/120000 [00:05<00:06, 10199.92 examples/s]\u001b[A\n",
            "Generating train examples...:  46% 55001/120000 [00:05<00:06, 10319.03 examples/s]\u001b[A\n",
            "Generating train examples...:  47% 56045/120000 [00:05<00:06, 10354.62 examples/s]\u001b[A\n",
            "Generating train examples...:  48% 57123/120000 [00:05<00:06, 10478.42 examples/s]\u001b[A\n",
            "Generating train examples...:  48% 58189/120000 [00:05<00:05, 10528.69 examples/s]\u001b[A\n",
            "Generating train examples...:  49% 59243/120000 [00:05<00:06, 9951.60 examples/s] \u001b[A\n",
            "Generating train examples...:  50% 60284/120000 [00:06<00:05, 10081.03 examples/s]\u001b[A\n",
            "Generating train examples...:  51% 61367/120000 [00:06<00:05, 10297.67 examples/s]\u001b[A\n",
            "Generating train examples...:  52% 62402/120000 [00:06<00:05, 10167.22 examples/s]\u001b[A\n",
            "Generating train examples...:  53% 63426/120000 [00:06<00:05, 10186.08 examples/s]\u001b[A\n",
            "Generating train examples...:  54% 64470/120000 [00:06<00:05, 10258.65 examples/s]\u001b[A\n",
            "Generating train examples...:  55% 65501/120000 [00:06<00:05, 10271.36 examples/s]\u001b[A\n",
            "Generating train examples...:  55% 66580/120000 [00:06<00:05, 10423.42 examples/s]\u001b[A\n",
            "Generating train examples...:  56% 67624/120000 [00:06<00:05, 10245.59 examples/s]\u001b[A\n",
            "Generating train examples...:  57% 68650/120000 [00:07<00:09, 5380.53 examples/s] \u001b[A\n",
            "Generating train examples...:  58% 69444/120000 [00:07<00:08, 5771.99 examples/s]\u001b[A\n",
            "Generating train examples...:  59% 70437/120000 [00:07<00:07, 6617.10 examples/s]\u001b[A\n",
            "Generating train examples...:  60% 71457/120000 [00:07<00:06, 7423.81 examples/s]\u001b[A\n",
            "Generating train examples...:  60% 72484/120000 [00:07<00:05, 8115.38 examples/s]\u001b[A\n",
            "Generating train examples...:  61% 73525/120000 [00:07<00:05, 8706.95 examples/s]\u001b[A\n",
            "Generating train examples...:  62% 74492/120000 [00:07<00:05, 7750.74 examples/s]\u001b[A\n",
            "Generating train examples...:  63% 75353/120000 [00:08<00:08, 5026.69 examples/s]\u001b[A\n",
            "Generating train examples...:  64% 76360/120000 [00:08<00:07, 5952.54 examples/s]\u001b[A\n",
            "Generating train examples...:  64% 77400/120000 [00:08<00:06, 6876.33 examples/s]\u001b[A\n",
            "Generating train examples...:  65% 78393/120000 [00:08<00:05, 7574.67 examples/s]\u001b[A\n",
            "Generating train examples...:  66% 79418/120000 [00:08<00:04, 8231.45 examples/s]\u001b[A\n",
            "Generating train examples...:  67% 80477/120000 [00:08<00:04, 8843.98 examples/s]\u001b[A\n",
            "Generating train examples...:  68% 81507/120000 [00:08<00:04, 9237.00 examples/s]\u001b[A\n",
            "Generating train examples...:  69% 82559/120000 [00:08<00:03, 9593.23 examples/s]\u001b[A\n",
            "Generating train examples...:  70% 83567/120000 [00:08<00:03, 9513.10 examples/s]\u001b[A\n",
            "Generating train examples...:  70% 84553/120000 [00:09<00:03, 9599.79 examples/s]\u001b[A\n",
            "Generating train examples...:  71% 85595/120000 [00:09<00:03, 9834.88 examples/s]\u001b[A\n",
            "Generating train examples...:  72% 86621/120000 [00:09<00:03, 9956.37 examples/s]\u001b[A\n",
            "Generating train examples...:  73% 87630/120000 [00:09<00:03, 9962.05 examples/s]\u001b[A\n",
            "Generating train examples...:  74% 88650/120000 [00:09<00:03, 10029.58 examples/s]\u001b[A\n",
            "Generating train examples...:  75% 89698/120000 [00:09<00:02, 10161.99 examples/s]\u001b[A\n",
            "Generating train examples...:  76% 90719/120000 [00:09<00:02, 10111.17 examples/s]\u001b[A\n",
            "Generating train examples...:  76% 91734/120000 [00:09<00:02, 10080.82 examples/s]\u001b[A\n",
            "Generating train examples...:  77% 92752/120000 [00:09<00:02, 10109.72 examples/s]\u001b[A\n",
            "Generating train examples...:  78% 93765/120000 [00:09<00:02, 9925.23 examples/s] \u001b[A\n",
            "Generating train examples...:  79% 94781/120000 [00:10<00:02, 9993.09 examples/s]\u001b[A\n",
            "Generating train examples...:  80% 95814/120000 [00:10<00:02, 10092.50 examples/s]\u001b[A\n",
            "Generating train examples...:  81% 96869/120000 [00:10<00:02, 10226.19 examples/s]\u001b[A\n",
            "Generating train examples...:  82% 97893/120000 [00:10<00:02, 10184.96 examples/s]\u001b[A\n",
            "Generating train examples...:  82% 98913/120000 [00:10<00:02, 10175.56 examples/s]\u001b[A\n",
            "Generating train examples...:  83% 99943/120000 [00:10<00:01, 10211.52 examples/s]\u001b[A\n",
            "Generating train examples...:  84% 100984/120000 [00:10<00:01, 10269.33 examples/s]\u001b[A\n",
            "Generating train examples...:  85% 102066/120000 [00:10<00:01, 10433.03 examples/s]\u001b[A\n",
            "Generating train examples...:  86% 103111/120000 [00:10<00:01, 10437.41 examples/s]\u001b[A\n",
            "Generating train examples...:  87% 104155/120000 [00:10<00:01, 10060.41 examples/s]\u001b[A\n",
            "Generating train examples...:  88% 105203/120000 [00:11<00:01, 10180.58 examples/s]\u001b[A\n",
            "Generating train examples...:  89% 106224/120000 [00:11<00:01, 9729.96 examples/s] \u001b[A\n",
            "Generating train examples...:  89% 107281/120000 [00:11<00:01, 9969.75 examples/s]\u001b[A\n",
            "Generating train examples...:  90% 108283/120000 [00:11<00:01, 9952.08 examples/s]\u001b[A\n",
            "Generating train examples...:  91% 109282/120000 [00:11<00:01, 9685.32 examples/s]\u001b[A\n",
            "Generating train examples...:  92% 110355/120000 [00:11<00:00, 9984.90 examples/s]\u001b[A\n",
            "Generating train examples...:  93% 111409/120000 [00:11<00:00, 10144.55 examples/s]\u001b[A\n",
            "Generating train examples...:  94% 112443/120000 [00:11<00:00, 10199.58 examples/s]\u001b[A\n",
            "Generating train examples...:  95% 113518/120000 [00:11<00:00, 10360.15 examples/s]\u001b[A\n",
            "Generating train examples...:  95% 114556/120000 [00:11<00:00, 10169.63 examples/s]\u001b[A\n",
            "Generating train examples...:  96% 115575/120000 [00:12<00:00, 10169.48 examples/s]\u001b[A\n",
            "Generating train examples...:  97% 116639/120000 [00:12<00:00, 10306.85 examples/s]\u001b[A\n",
            "Generating train examples...:  98% 117709/120000 [00:12<00:00, 10421.69 examples/s]\u001b[A\n",
            "Generating train examples...:  99% 118753/120000 [00:12<00:00, 10156.83 examples/s]\u001b[A\n",
            "Generating train examples...: 100% 119771/120000 [00:12<00:00, 10031.58 examples/s]\u001b[A\n",
            "                                                                                   \u001b[A\n",
            "Shuffling /root/tensorflow_datasets/ag_news_subset/1.0.0.incompleteHKVLW7/ag_news_subset-train.tfrecord*...:   0% 0/120000 [00:00<?, ? examples/s]\u001b[A\n",
            "Shuffling /root/tensorflow_datasets/ag_news_subset/1.0.0.incompleteHKVLW7/ag_news_subset-train.tfrecord*...:   5% 6289/120000 [00:00<00:01, 62887.21 examples/s]\u001b[A\n",
            "Shuffling /root/tensorflow_datasets/ag_news_subset/1.0.0.incompleteHKVLW7/ag_news_subset-train.tfrecord*...:  48% 57603/120000 [00:00<00:00, 327729.33 examples/s]\u001b[A\n",
            "Shuffling /root/tensorflow_datasets/ag_news_subset/1.0.0.incompleteHKVLW7/ag_news_subset-train.tfrecord*...:  92% 110302/120000 [00:00<00:00, 418704.95 examples/s]\u001b[A\n",
            "INFO[writer.py]: Done writing /root/tensorflow_datasets/ag_news_subset/1.0.0.incompleteHKVLW7/ag_news_subset-train.tfrecord*. Number of examples: 120000 (shards: [120000])\n",
            "Generating splits...:  50% 1/2 [00:12<00:12, 12.88s/ splits]\n",
            "Generating test examples...:   0% 0/7600 [00:00<?, ? examples/s]\u001b[A\n",
            "Generating test examples...:  13% 992/7600 [00:00<00:00, 9914.45 examples/s]\u001b[A\n",
            "Generating test examples...:  26% 1984/7600 [00:00<00:00, 9420.63 examples/s]\u001b[A\n",
            "Generating test examples...:  40% 3069/7600 [00:00<00:00, 10053.15 examples/s]\u001b[A\n",
            "Generating test examples...:  55% 4151/7600 [00:00<00:00, 10347.88 examples/s]\u001b[A\n",
            "Generating test examples...:  68% 5199/7600 [00:00<00:00, 10391.23 examples/s]\u001b[A\n",
            "Generating test examples...:  82% 6242/7600 [00:00<00:00, 10402.69 examples/s]\u001b[A\n",
            "Generating test examples...:  97% 7339/7600 [00:00<00:00, 10586.10 examples/s]\u001b[A\n",
            "                                                                              \u001b[A\n",
            "Shuffling /root/tensorflow_datasets/ag_news_subset/1.0.0.incompleteHKVLW7/ag_news_subset-test.tfrecord*...:   0% 0/7600 [00:00<?, ? examples/s]\u001b[A\n",
            "INFO[writer.py]: Done writing /root/tensorflow_datasets/ag_news_subset/1.0.0.incompleteHKVLW7/ag_news_subset-test.tfrecord*. Number of examples: 7600 (shards: [7600])\n",
            "\u001b[1mDataset ag_news_subset downloaded and prepared to /root/tensorflow_datasets/ag_news_subset/1.0.0. Subsequent calls will reuse this data.\u001b[0m\n",
            "INFO[build.py]: Dataset generation complete...\n",
            "\n",
            "tfds.core.DatasetInfo(\n",
            "    name='ag_news_subset',\n",
            "    full_name='ag_news_subset/1.0.0',\n",
            "    description=\"\"\"\n",
            "    AG is a collection of more than 1 million news articles.\n",
            "    News articles have been gathered from more than 2000  news sources by ComeToMyHead in more than 1 year of activity.\n",
            "    ComeToMyHead is an academic news search engine which has been running since July, 2004.\n",
            "    The dataset is provided by the academic comunity for research purposes in data mining (clustering, classification, etc),\n",
            "    information retrieval (ranking, search, etc), xml, data compression, data streaming,\n",
            "    and any other non-commercial activity.\n",
            "    For more information, please refer to the link http://www.di.unipi.it/~gulli/AG_corpus_of_news_articles.html .\n",
            "    \n",
            "    The AG's news topic classification dataset is constructed by Xiang Zhang (xiang.zhang@nyu.edu) from the dataset above.\n",
            "    It is used as a text classification benchmark in the following paper:\n",
            "    Xiang Zhang, Junbo Zhao, Yann LeCun. Character-level Convolutional Networks for Text Classification. Advances in Neural Information Processing Systems 28 (NIPS 2015).\n",
            "    \n",
            "    The AG's news topic classification dataset is constructed by choosing 4 largest classes from the original corpus.\n",
            "    Each class contains 30,000 training samples and 1,900 testing samples.\n",
            "    The total number of training samples is 120,000 and testing 7,600.\n",
            "    \"\"\",\n",
            "    homepage='https://arxiv.org/abs/1509.01626',\n",
            "    data_path='/root/tensorflow_datasets/ag_news_subset/1.0.0',\n",
            "    file_format=tfrecord,\n",
            "    download_size=11.24 MiB,\n",
            "    dataset_size=35.79 MiB,\n",
            "    features=FeaturesDict({\n",
            "        'description': Text(shape=(), dtype=tf.string),\n",
            "        'label': ClassLabel(shape=(), dtype=tf.int64, num_classes=4),\n",
            "        'title': Text(shape=(), dtype=tf.string),\n",
            "    }),\n",
            "    supervised_keys=('description', 'label'),\n",
            "    disable_shuffling=False,\n",
            "    splits={\n",
            "        'test': <SplitInfo num_examples=7600, num_shards=1>,\n",
            "        'train': <SplitInfo num_examples=120000, num_shards=1>,\n",
            "    },\n",
            "    citation=\"\"\"@misc{zhang2015characterlevel,\n",
            "        title={Character-level Convolutional Networks for Text Classification},\n",
            "        author={Xiang Zhang and Junbo Zhao and Yann LeCun},\n",
            "        year={2015},\n",
            "        eprint={1509.01626},\n",
            "        archivePrefix={arXiv},\n",
            "        primaryClass={cs.LG}\n",
            "    }\"\"\",\n",
            ")\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# register  ag_news_subset so that tfds.load doesn't generate a checksum (mismatch) error\n",
        "!python -m tensorflow_datasets.scripts.download_and_prepare --register_checksums --datasets=ag_news_subset\n",
        "\n",
        "dataset,info=\\\n",
        "tfds.load('ag_news_subset', with_info=True,  split=['train[:95%]','train[95%:]', 'test'],batch_size = 32\n",
        "          , as_supervised=True)\n",
        "\n",
        "train_ds, val_ds, test_ds = dataset\n",
        "text_only_train_ds = train_ds.map(lambda x, y: x)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## EDA"
      ],
      "metadata": {
        "id": "iEsJEu39rCru"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "type(train_ds)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jARV90NqrqMB",
        "outputId": "dda7e0ef-5779-44ec-a17e-2f6448c8626d"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensorflow.python.data.ops.dataset_ops.PrefetchDataset"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "categories = {0: 'World', 1: 'Sports', 2: 'Business', 3: 'Sci/Tech'}\n",
        "all_df.Label.value_counts(sort=False).rename(index=categories)"
      ],
      "metadata": {
        "id": "Ynm5byxurFXj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mq7Q6zlFRro_"
      },
      "source": [
        "## Preparing Integer Sequence Datasets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XzuiyImJxreh",
        "outputId": "19229a84-4681-4227-dbae-b9bb038fbe0b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        }
      ],
      "source": [
        "nltk.download('stopwords')\n",
        "STOPWORDS = stopwords.words(\"english\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "AfTnCGIERrpA"
      },
      "outputs": [],
      "source": [
        "max_length = 150\n",
        "max_tokens = 1000\n",
        "text_vectorization = layers.TextVectorization(\n",
        "    max_tokens=max_tokens,\n",
        "    output_mode=\"int\",\n",
        "    output_sequence_length=max_length,\n",
        "    standardize=custom_stopwords\n",
        ")\n",
        "text_vectorization.adapt(text_only_train_ds)\n",
        "\n",
        "int_train_ds = train_ds.map(\n",
        "    lambda x, y: (text_vectorization(x), y),\n",
        "    num_parallel_calls=4)\n",
        "int_val_ds = val_ds.map(\n",
        "    lambda x, y: (text_vectorization(x), y),\n",
        "    num_parallel_calls=4)\n",
        "int_test_ds = test_ds.map(\n",
        "    lambda x, y: (text_vectorization(x), y),\n",
        "    num_parallel_calls=4)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NBL0CkaB5ukv"
      },
      "source": [
        "## Bi-directional RNN\n",
        "\n",
        "When translating in real-time, it would help to have access to worlds towards the end of a sentence, say, as well as earlier words in the sentence. One way to use the later words in the sentence is to feed the words into our RNN backward. So if we create two independent RNNs, we can feed one the words in their forward, or natural order, and the second gets their words in the revser order. This is the idea behind `Bi-directional RNNS`:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qN2wjSjdRrpB"
      },
      "source": [
        "## Sequence Model Built on One-Hot Encoded Vector Sequences"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Hq6dB-zWRrpB",
        "outputId": "241f4b82-f43b-4e46-9aeb-055f38b923da"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_1 (InputLayer)        [(None, None)]            0         \n",
            "                                                                 \n",
            " tf.one_hot (TFOpLambda)     (None, None, 1000)        0         \n",
            "                                                                 \n",
            " bidirectional (Bidirectiona  (None, 64)               264448    \n",
            " l)                                                              \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 64)                0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 4)                 260       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 264,708\n",
            "Trainable params: 264,708\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "inputs = tf.keras.Input(shape=(None,), dtype=\"int64\")\n",
        "embedded = tf.one_hot(inputs, depth=max_tokens)\n",
        "x = layers.Bidirectional(layers.LSTM(32))(embedded)\n",
        "x = layers.Dropout(0.5)(x)\n",
        "outputs = layers.Dense(4, activation=\"softmax\")(x)\n",
        "model = tf.keras.Model(inputs, outputs)\n",
        "model.compile(optimizer=\"rmsprop\",\n",
        "              loss=\"SparseCategoricalCrossentropy\",\n",
        "              metrics=[\"accuracy\"])\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R64NWZQc5ukx"
      },
      "source": [
        "## One input is a sequence of integers.\n",
        "\n",
        "1. In order to keep a manageable input size, we’ll truncate the inputs after the first 150 words. This is a reasonable choice, since the average review length is 233 words, and only 5% of reviews are longer than 150 words.\n",
        "\n",
        "2. Encode the integers into binary 1,000-dimensional vectors.\n",
        "\n",
        "3. Add a bidirectional LSTM.\n",
        "\n",
        "4. Finally, add a classification layer."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ognTeJM6RrpC"
      },
      "source": [
        "## Training Sequence Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5kCbHrrsRrpC",
        "outputId": "e3ce36bb-edad-4e6b-f246-16c650d328c2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/200\n",
            "3563/3563 [==============================] - 75s 19ms/step - loss: 0.5794 - accuracy: 0.7941 - val_loss: 0.4140 - val_accuracy: 0.8547\n",
            "Epoch 2/200\n",
            "3563/3563 [==============================] - 59s 17ms/step - loss: 0.4368 - accuracy: 0.8504 - val_loss: 0.4030 - val_accuracy: 0.8588\n",
            "Epoch 3/200\n",
            "3563/3563 [==============================] - 63s 18ms/step - loss: 0.4225 - accuracy: 0.8555 - val_loss: 0.3986 - val_accuracy: 0.8597\n",
            "Epoch 4/200\n",
            "3563/3563 [==============================] - 59s 16ms/step - loss: 0.4125 - accuracy: 0.8572 - val_loss: 0.3956 - val_accuracy: 0.8608\n",
            "Epoch 5/200\n",
            "3563/3563 [==============================] - 58s 16ms/step - loss: 0.4048 - accuracy: 0.8608 - val_loss: 0.3933 - val_accuracy: 0.8590\n",
            "Epoch 6/200\n",
            "3563/3563 [==============================] - 58s 16ms/step - loss: 0.4012 - accuracy: 0.8623 - val_loss: 0.3937 - val_accuracy: 0.8600\n",
            "Epoch 7/200\n",
            "3563/3563 [==============================] - 57s 16ms/step - loss: 0.3954 - accuracy: 0.8641 - val_loss: 0.3961 - val_accuracy: 0.8607\n",
            "238/238 [==============================] - 3s 10ms/step - loss: 0.4022 - accuracy: 0.8588\n",
            "Test acc: 0.859\n"
          ]
        }
      ],
      "source": [
        "callbacks = [\n",
        "    tf.keras.callbacks.ModelCheckpoint(\"one_hot_bidir_lstm.keras\",\n",
        "                                    save_best_only=True)\n",
        "    ,tf.keras.callbacks.EarlyStopping(monitor='val_accuracy', patience=3)\n",
        "]\n",
        "model.fit(int_train_ds, validation_data=int_val_ds, epochs=200, callbacks=callbacks)\n",
        "model = keras.models.load_model(\"one_hot_bidir_lstm.keras\")\n",
        "print(f\"Test acc: {model.evaluate(int_test_ds)[1]:.3f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fTprEi3bRrpD"
      },
      "source": [
        "## Understanding word embeddings"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pmHdhUnM5ukz"
      },
      "source": [
        "When you encode something via `one-hot encoding`, you’re making a feature-engineering decision. You’re injecting into your model a fundamental assumption about the structure of your feature space. That assumption is that the different tokens you’re encoding are all independent from each other: indeed, one-hot vectors are all orthogonal to one another."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "webaWkZJ5ukz"
      },
      "source": [
        "However, in a reasonable word vector space, you would expect synonyms to be embedded into similar word vectors, and in general, you would expect the geometric distance  between any two word vectors to relate to the “semantic distance” between the associated words.\n",
        "\n",
        "Words that mean different things should lie far away from each other, whereas related words should be closer."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b-W1sFgg5ukz"
      },
      "source": [
        "`Word embeddings` are vector representations of words that achieve exactly this: they map human language into a structured geometric space."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0egzHasW5ukz"
      },
      "source": [
        "Whereas the vectors obtained through `one-hot encoding` are *binary*, *sparse*, and *very high-dimensional* (the same dimensionality as the number of words in the vocabulary), `word embeddings` are *low-dimensional floating-point vectors* (that is, `dense vectors`, as opposed to `sparse vectors`)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "im1j5PRE5uk0"
      },
      "source": [
        "## Two ways to obtain word embeddings\n",
        "\n",
        "1. `Learn word embeddings jointly with the main task you care about` (such as document classification or sentiment prediction). In this setup, you start with random word vectors and then learn word vectors in the same way you learn the weights of a neural network.\n",
        "2. Load into your model word embeddings that were precomputed using a different machine learning task than the one you’re trying to solve. These are called `pretrained word embeddings`.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0CNyH_fhRrpD"
      },
      "source": [
        "## Learning Word Embeddings With The Embedding Layer"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LsYLfdJY5uk0"
      },
      "source": [
        "What makes a good word-embedding space depends heavily on your task: the perfect word-embedding space for an English-language movie-review sentiment-analysis model may look different from the perfect embedding space for an English-language legal-document classification model, because the importance of certain semantic relationships varies from task to task.\n",
        "\n",
        "It’s thus reasonable to learn a new embedding space with every new task."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NrVeqKcsRrpE"
      },
      "source": [
        "## Instantiating An Embedding Layer\n",
        "\n",
        "The Embedding layer takes at least two arguments: the number of possible tokens and the dimensionality of the embeddings (here, 256)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "WLTjxbMnRrpE"
      },
      "outputs": [],
      "source": [
        "embedding_layer = layers.Embedding(input_dim=max_tokens, output_dim=256)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vWx26f9C5uk2"
      },
      "source": [
        "The Embedding layer is best understood as a dictionary that maps integer indices (which stand for specific words) to dense vectors"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PSfWWNO6RrpE"
      },
      "source": [
        "## Model Leveraging Trained Embedding Layer"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FLuGKCM35uk2"
      },
      "source": [
        "One input is a sequence of integers.\n",
        "1. Encode the integers into binary 20,000-dimensional vectors.\n",
        "2. Add a bidirectional LSTM.\n",
        "3. Finally, add a classification layer."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O6JFON-CRrpF",
        "outputId": "309f443a-51b6-4071-da04-0aed1e5dc5e2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_2 (InputLayer)        [(None, None)]            0         \n",
            "                                                                 \n",
            " embedding_1 (Embedding)     (None, None, 256)         256000    \n",
            "                                                                 \n",
            " bidirectional_1 (Bidirectio  (None, 64)               73984     \n",
            " nal)                                                            \n",
            "                                                                 \n",
            " dropout_1 (Dropout)         (None, 64)                0         \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 4)                 260       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 330,244\n",
            "Trainable params: 330,244\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/200\n",
            "3563/3563 [==============================] - 68s 18ms/step - loss: 0.4981 - accuracy: 0.8276 - val_loss: 0.4086 - val_accuracy: 0.8573\n",
            "Epoch 2/200\n",
            "3563/3563 [==============================] - 58s 16ms/step - loss: 0.4294 - accuracy: 0.8520 - val_loss: 0.3992 - val_accuracy: 0.8612\n",
            "Epoch 3/200\n",
            "3563/3563 [==============================] - 58s 16ms/step - loss: 0.4146 - accuracy: 0.8574 - val_loss: 0.3853 - val_accuracy: 0.8633\n",
            "Epoch 4/200\n",
            "3563/3563 [==============================] - 58s 16ms/step - loss: 0.4019 - accuracy: 0.8607 - val_loss: 0.3835 - val_accuracy: 0.8620\n",
            "Epoch 5/200\n",
            "3563/3563 [==============================] - 61s 17ms/step - loss: 0.3952 - accuracy: 0.8630 - val_loss: 0.3804 - val_accuracy: 0.8652\n",
            "Epoch 6/200\n",
            "3563/3563 [==============================] - 60s 17ms/step - loss: 0.3887 - accuracy: 0.8656 - val_loss: 0.3831 - val_accuracy: 0.8618\n",
            "Epoch 7/200\n",
            "3563/3563 [==============================] - 57s 16ms/step - loss: 0.3824 - accuracy: 0.8676 - val_loss: 0.3826 - val_accuracy: 0.8668\n",
            "Epoch 8/200\n",
            "3563/3563 [==============================] - 64s 18ms/step - loss: 0.3773 - accuracy: 0.8701 - val_loss: 0.3795 - val_accuracy: 0.8623\n",
            "Epoch 9/200\n",
            "3563/3563 [==============================] - 58s 16ms/step - loss: 0.3726 - accuracy: 0.8716 - val_loss: 0.3788 - val_accuracy: 0.8615\n",
            "Epoch 10/200\n",
            "3563/3563 [==============================] - 60s 17ms/step - loss: 0.3675 - accuracy: 0.8721 - val_loss: 0.3887 - val_accuracy: 0.8620\n",
            "238/238 [==============================] - 3s 8ms/step - loss: 0.3937 - accuracy: 0.8661\n",
            "Test acc: 0.866\n"
          ]
        }
      ],
      "source": [
        "inputs = tf.keras.Input(shape=(None,), dtype=\"int64\")\n",
        "embedded = layers.Embedding(input_dim=max_tokens, output_dim=256)(inputs)\n",
        "x = layers.Bidirectional(layers.LSTM(32))(embedded)\n",
        "x = layers.Dropout(0.5)(x)\n",
        "outputs = layers.Dense(4, activation=\"softmax\")(x)\n",
        "model = tf.keras.Model(inputs, outputs)\n",
        "model.compile(optimizer=\"rmsprop\",\n",
        "              loss=\"SparseCategoricalCrossentropy\",\n",
        "              metrics=[\"accuracy\"])\n",
        "model.summary()\n",
        "\n",
        "callbacks = [\n",
        "    tf.keras.callbacks.ModelCheckpoint(\"embeddings_bidir_gru.keras\",\n",
        "                                    save_best_only=True)\n",
        "    ,tf.keras.callbacks.EarlyStopping(monitor='val_accuracy', patience=3)\n",
        "]\n",
        "model.fit(int_train_ds, validation_data=int_val_ds, epochs=200, callbacks=callbacks)\n",
        "model = keras.models.load_model(\"embeddings_bidir_gru.keras\")\n",
        "print(f\"Test acc: {model.evaluate(int_test_ds)[1]:.3f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HHF_wA3x5uk3"
      },
      "source": [
        "It trains much faster than the one-hot model (since the LSTM only has to process 256-dimensional vectors instead of 1,000-dimensional), and its test accuracy is comparable (86%)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M0gOTdNnRrpF"
      },
      "source": [
        "## Understanding Padding and Masking"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HGe0pvoxRrpF"
      },
      "source": [
        "## Model Leveraging Embedding Layer With Masking Enabled"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tU6YKNrDRrpF",
        "outputId": "580f4b90-c93d-4d22-bd12-ec392dfbd0e7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_2\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_3 (InputLayer)        [(None, None)]            0         \n",
            "                                                                 \n",
            " embedding_2 (Embedding)     (None, None, 256)         256000    \n",
            "                                                                 \n",
            " bidirectional_2 (Bidirectio  (None, 64)               73984     \n",
            " nal)                                                            \n",
            "                                                                 \n",
            " dropout_2 (Dropout)         (None, 64)                0         \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 4)                 260       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 330,244\n",
            "Trainable params: 330,244\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/200\n",
            "3563/3563 [==============================] - 69s 18ms/step - loss: 0.4738 - accuracy: 0.8332 - val_loss: 0.4014 - val_accuracy: 0.8580\n",
            "Epoch 2/200\n",
            "3563/3563 [==============================] - 55s 15ms/step - loss: 0.4134 - accuracy: 0.8545 - val_loss: 0.3922 - val_accuracy: 0.8633\n",
            "Epoch 3/200\n",
            "3563/3563 [==============================] - 55s 15ms/step - loss: 0.4000 - accuracy: 0.8590 - val_loss: 0.3873 - val_accuracy: 0.8642\n",
            "Epoch 4/200\n",
            "3563/3563 [==============================] - 55s 15ms/step - loss: 0.3892 - accuracy: 0.8630 - val_loss: 0.3820 - val_accuracy: 0.8632\n",
            "Epoch 5/200\n",
            "3563/3563 [==============================] - 62s 17ms/step - loss: 0.3805 - accuracy: 0.8665 - val_loss: 0.3783 - val_accuracy: 0.8650\n",
            "Epoch 6/200\n",
            "3563/3563 [==============================] - 54s 15ms/step - loss: 0.3726 - accuracy: 0.8695 - val_loss: 0.3806 - val_accuracy: 0.8652\n",
            "Epoch 7/200\n",
            "3563/3563 [==============================] - 54s 15ms/step - loss: 0.3652 - accuracy: 0.8719 - val_loss: 0.3835 - val_accuracy: 0.8678\n",
            "Epoch 8/200\n",
            "3563/3563 [==============================] - 54s 15ms/step - loss: 0.3597 - accuracy: 0.8747 - val_loss: 0.3838 - val_accuracy: 0.8685\n",
            "Epoch 9/200\n",
            "3563/3563 [==============================] - 56s 16ms/step - loss: 0.3526 - accuracy: 0.8774 - val_loss: 0.3866 - val_accuracy: 0.8660\n",
            "Epoch 10/200\n",
            "3563/3563 [==============================] - 60s 17ms/step - loss: 0.3438 - accuracy: 0.8800 - val_loss: 0.3955 - val_accuracy: 0.8665\n",
            "Epoch 11/200\n",
            "3563/3563 [==============================] - 54s 15ms/step - loss: 0.3378 - accuracy: 0.8822 - val_loss: 0.3953 - val_accuracy: 0.8667\n",
            "238/238 [==============================] - 4s 6ms/step - loss: 0.3920 - accuracy: 0.8629\n",
            "Test acc: 0.863\n"
          ]
        }
      ],
      "source": [
        "inputs = tf.keras.Input(shape=(None,), dtype=\"int64\")\n",
        "embedded = layers.Embedding(\n",
        "    input_dim=max_tokens, output_dim=256, mask_zero=True)(inputs)\n",
        "x = layers.Bidirectional(layers.LSTM(32))(embedded)\n",
        "x = layers.Dropout(0.5)(x)\n",
        "outputs = layers.Dense(4, activation=\"softmax\")(x)\n",
        "model = tf.keras.Model(inputs, outputs)\n",
        "model.compile(optimizer=\"rmsprop\",\n",
        "              loss=\"SparseCategoricalCrossentropy\",\n",
        "              metrics=[\"accuracy\"])\n",
        "model.summary()\n",
        "\n",
        "callbacks = [\n",
        "    tf.keras.callbacks.ModelCheckpoint(\"embeddings_bidir_gru_with_masking.keras\",\n",
        "                                    save_best_only=True)\n",
        "    ,tf.keras.callbacks.EarlyStopping(monitor='val_accuracy', patience=3)\n",
        "]\n",
        "model.fit(int_train_ds, validation_data=int_val_ds, epochs=200, callbacks=callbacks)\n",
        "model = keras.models.load_model(\"embeddings_bidir_gru_with_masking.keras\")\n",
        "print(f\"Test acc: {model.evaluate(int_test_ds)[1]:.3f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SDRunHYSRrpG"
      },
      "source": [
        "## Using Pretrained Word Embeddings"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ivO55Vo15uk6"
      },
      "source": [
        "The rationale behind using `pretrained word embedding`s in natural language processing is much the same as for using pretrained convnets in image classification: *you don’t have enough data available to learn truly powerful features on your own*, but you expect that the features you need are fairly generic—that is, common visual features or semantic features. In this case, it makes sense to reuse features learned on a different problem."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XllLQfXb5uk6"
      },
      "source": [
        "The idea of a dense, low-dimensional embedding space for words, computed in an unsupervised way, was initially explored by Bengio et al. in the early 2000s, but it only started to take off in research and industry applications after the release of one of the most famous and successful word-embedding schemes: the `Word2Vec` algorithm (https://code.google.com/archive/p/word2vec), developed by Tomas Mikolov at Google in 2013. `Word2Vec` dimensions capture specific semantic properties, such as gender."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "riqJwrpr5uk6"
      },
      "source": [
        "There are various precomputed databases of word embeddings that you can download and use in a Keras Embedding layer. `Word2vec` is one of them. Another popular one is called `Global Vectors for Word Representatio`n (GloVe, https://nlp.stanford.edu/projects/glove), which was developed by Stanford researchers in 2014. This embedding technique is based on factorizing a matrix of word co-occurrence statistics. Its developers have made available precomputed embeddings for millions of English tokens, obtained from Wikipedia data and Common Crawl data."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oKNrxDE65uk6"
      },
      "source": [
        "First, let’s download the GloVe word embeddings precomputed on the 2014 English Wikipedia dataset. It’s an 822 MB zip file containing 100-dimensional embedding vectors for 400,000 words (or non-word tokens)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5P6O5iXN5uk7"
      },
      "source": [
        "<div class=\"alert alert-block alert-success\"><b>GloVe: Global Vectors for Word Representation</b><br>\n",
        "https://nlp.stanford.edu/projects/glove/</div>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-EjBZq6cRrpG",
        "outputId": "62128009-f87c-4a28-9135-7cbc07c77112"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2022-11-04 17:20:22--  http://nlp.stanford.edu/data/glove.6B.zip\n",
            "Resolving nlp.stanford.edu (nlp.stanford.edu)... 171.64.67.140\n",
            "Connecting to nlp.stanford.edu (nlp.stanford.edu)|171.64.67.140|:80... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://nlp.stanford.edu/data/glove.6B.zip [following]\n",
            "--2022-11-04 17:20:23--  https://nlp.stanford.edu/data/glove.6B.zip\n",
            "Connecting to nlp.stanford.edu (nlp.stanford.edu)|171.64.67.140|:443... connected.\n",
            "HTTP request sent, awaiting response... 301 Moved Permanently\n",
            "Location: https://downloads.cs.stanford.edu/nlp/data/glove.6B.zip [following]\n",
            "--2022-11-04 17:20:23--  https://downloads.cs.stanford.edu/nlp/data/glove.6B.zip\n",
            "Resolving downloads.cs.stanford.edu (downloads.cs.stanford.edu)... 171.64.64.22\n",
            "Connecting to downloads.cs.stanford.edu (downloads.cs.stanford.edu)|171.64.64.22|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 862182613 (822M) [application/zip]\n",
            "Saving to: ‘glove.6B.zip’\n",
            "\n",
            "glove.6B.zip        100%[===================>] 822.24M  5.01MB/s    in 2m 39s  \n",
            "\n",
            "2022-11-04 17:23:03 (5.17 MB/s) - ‘glove.6B.zip’ saved [862182613/862182613]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!wget http://nlp.stanford.edu/data/glove.6B.zip\n",
        "!unzip -q glove.6B.zip"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o4Ifl-sJRrpH"
      },
      "source": [
        "## Parsing The GloVe Word-Embeddings File\n",
        "\n",
        "First line of `glove.6B.100d.txt`:\n",
        "\n",
        "`the -0.038194 -0.24487 0.72812 ...`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VPo9aWdbRrpH",
        "outputId": "f90acd31-1231-4293-bb7d-f7c3710909e8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 400000 word vectors.\n"
          ]
        }
      ],
      "source": [
        "path_to_glove_file = \"glove.6B.100d.txt\"\n",
        "\n",
        "embeddings_index = {}\n",
        "with open(path_to_glove_file) as f:\n",
        "    for line in f:\n",
        "        word, coefs = line.split(maxsplit=1)\n",
        "        coefs = np.fromstring(coefs, \"f\", sep=\" \") # np.dtype('f') returns dtype('float32')\n",
        "        embeddings_index[word] = coefs\n",
        "\n",
        "print(f\"Found {len(embeddings_index)} word vectors.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "evKxdRndRrpH"
      },
      "source": [
        "## Preparing The GloVe Word-Embeddings Matrix\n",
        "\n",
        "Next, let’s build an embedding matrix that you can load into an Embedding layer. It must be a matrix of shape `(max_words, embedding_dim)`, where each entry *i* contains the `embedding_dim`-dimensional vector for the word of index *i* in the reference word index (built during tokenization)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "jSCD2_KcRrpI"
      },
      "outputs": [],
      "source": [
        "embedding_dim = 100\n",
        "\n",
        "# Retrieve the vocabulary indexed by our previous TextVectorization layer.\n",
        "vocabulary = text_vectorization.get_vocabulary()\n",
        "\n",
        "# Use it to create a mapping from words to their index in the vocabulary.\n",
        "word_index = dict(zip(vocabulary, range(len(vocabulary))))\n",
        "\n",
        "# Prepare a matrix that we’ll fill with the GloVe vectors.\n",
        "embedding_matrix = np.zeros((max_tokens, embedding_dim))\n",
        "\n",
        "# Fill entry i in the matrix with the word vector for index i.\n",
        "for word, i in word_index.items():\n",
        "    if i < max_tokens:\n",
        "        embedding_vector = embeddings_index.get(word)\n",
        "    if embedding_vector is not None:  # Words not found in the embedding index will be all zeros.\n",
        "        embedding_matrix[i] = embedding_vector"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "ZE2xRs4QRrpI"
      },
      "outputs": [],
      "source": [
        "embedding_layer = layers.Embedding(\n",
        "    max_tokens,\n",
        "    embedding_dim,\n",
        "    embeddings_initializer=keras.initializers.Constant(embedding_matrix),\n",
        "    trainable=False,\n",
        "    mask_zero=True,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PUsE9u-g5uk9"
      },
      "source": [
        "We’re now ready to train a new model—identical to our previous model, but leveraging the `100-dimensional` pretrained GloVe embeddings instead of `256-dimensional` learned embeddings."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2aXYeW8o5uk9"
      },
      "source": [
        "## One possible alternative to GloVE: ELMo (Embedding from Language Models)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VOA_ss3iRrpJ"
      },
      "source": [
        "## Model Leveraging Pretrained (GloVe) Embedding Layer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RI8Tj4g1RrpJ",
        "outputId": "3708ed3e-9514-44b8-eaf9-06f7b7f6cf07",
        "scrolled": false
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_3\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_4 (InputLayer)        [(None, None)]            0         \n",
            "                                                                 \n",
            " embedding_3 (Embedding)     (None, None, 100)         100000    \n",
            "                                                                 \n",
            " bidirectional_3 (Bidirectio  (None, 64)               34048     \n",
            " nal)                                                            \n",
            "                                                                 \n",
            " dropout_3 (Dropout)         (None, 64)                0         \n",
            "                                                                 \n",
            " dense_3 (Dense)             (None, 4)                 260       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 134,308\n",
            "Trainable params: 34,308\n",
            "Non-trainable params: 100,000\n",
            "_________________________________________________________________\n",
            "Epoch 1/200\n",
            "3563/3563 [==============================] - 62s 15ms/step - loss: 0.4828 - accuracy: 0.8287 - val_loss: 0.4095 - val_accuracy: 0.8522\n",
            "Epoch 2/200\n",
            "3563/3563 [==============================] - 49s 14ms/step - loss: 0.4249 - accuracy: 0.8475 - val_loss: 0.3939 - val_accuracy: 0.8552\n",
            "Epoch 3/200\n",
            "3563/3563 [==============================] - 55s 15ms/step - loss: 0.4047 - accuracy: 0.8542 - val_loss: 0.3846 - val_accuracy: 0.8610\n",
            "Epoch 4/200\n",
            "3563/3563 [==============================] - 52s 15ms/step - loss: 0.3955 - accuracy: 0.8578 - val_loss: 0.3806 - val_accuracy: 0.8620\n",
            "Epoch 5/200\n",
            "3563/3563 [==============================] - 54s 15ms/step - loss: 0.3857 - accuracy: 0.8615 - val_loss: 0.3794 - val_accuracy: 0.8618\n",
            "Epoch 6/200\n",
            "3563/3563 [==============================] - 52s 15ms/step - loss: 0.3786 - accuracy: 0.8629 - val_loss: 0.3782 - val_accuracy: 0.8627\n",
            "Epoch 7/200\n",
            "3563/3563 [==============================] - 50s 14ms/step - loss: 0.3711 - accuracy: 0.8665 - val_loss: 0.3780 - val_accuracy: 0.8627\n",
            "Epoch 8/200\n",
            "3563/3563 [==============================] - 50s 14ms/step - loss: 0.3662 - accuracy: 0.8673 - val_loss: 0.3783 - val_accuracy: 0.8620\n",
            "Epoch 9/200\n",
            "3563/3563 [==============================] - 49s 14ms/step - loss: 0.3624 - accuracy: 0.8691 - val_loss: 0.3872 - val_accuracy: 0.8638\n",
            "Epoch 10/200\n",
            "3563/3563 [==============================] - 54s 15ms/step - loss: 0.3573 - accuracy: 0.8719 - val_loss: 0.3866 - val_accuracy: 0.8620\n",
            "Epoch 11/200\n",
            "3563/3563 [==============================] - 51s 14ms/step - loss: 0.3528 - accuracy: 0.8728 - val_loss: 0.3836 - val_accuracy: 0.8620\n",
            "Epoch 12/200\n",
            "3563/3563 [==============================] - 49s 14ms/step - loss: 0.3487 - accuracy: 0.8739 - val_loss: 0.3835 - val_accuracy: 0.8640\n",
            "Epoch 13/200\n",
            "3563/3563 [==============================] - 49s 14ms/step - loss: 0.3456 - accuracy: 0.8758 - val_loss: 0.3918 - val_accuracy: 0.8610\n",
            "Epoch 14/200\n",
            "3563/3563 [==============================] - 53s 15ms/step - loss: 0.3395 - accuracy: 0.8780 - val_loss: 0.3963 - val_accuracy: 0.8623\n",
            "Epoch 15/200\n",
            "3563/3563 [==============================] - 50s 14ms/step - loss: 0.3373 - accuracy: 0.8790 - val_loss: 0.4007 - val_accuracy: 0.8602\n",
            "238/238 [==============================] - 4s 6ms/step - loss: 0.3837 - accuracy: 0.8620\n",
            "Test acc: 0.862\n"
          ]
        }
      ],
      "source": [
        "inputs = tf.keras.Input(shape=(None,), dtype=\"int64\")\n",
        "embedded = embedding_layer(inputs)\n",
        "x = layers.Bidirectional(layers.LSTM(32))(embedded)\n",
        "x = layers.Dropout(0.5)(x)\n",
        "outputs = layers.Dense(4, activation=\"softmax\")(x)\n",
        "model = tf.keras.Model(inputs, outputs)\n",
        "model.compile(optimizer=\"rmsprop\",\n",
        "              loss=\"SparseCategoricalCrossentropy\",\n",
        "              metrics=[\"accuracy\"])\n",
        "model.summary()\n",
        "\n",
        "callbacks = [\n",
        "    tf.keras.callbacks.ModelCheckpoint(\"glove_embeddings_sequence_model.keras\",\n",
        "                                    save_best_only=True)\n",
        "    ,tf.keras.callbacks.EarlyStopping(monitor='val_accuracy', patience=3)\n",
        "]\n",
        "model.fit(int_train_ds, validation_data=int_val_ds, epochs=200, callbacks=callbacks)\n",
        "model = keras.models.load_model(\"glove_embeddings_sequence_model.keras\")\n",
        "print(f\"Test acc: {model.evaluate(int_test_ds)[1]:.3f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "5fqFXCOO5uk-"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "Ydgzc1l15ukl",
        "z1Gn6wYG5uks"
      ],
      "machine_shape": "hm",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.10"
    },
    "gpuClass": "standard"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}