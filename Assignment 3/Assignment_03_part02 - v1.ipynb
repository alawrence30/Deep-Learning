{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/alawrence30/Deep-Learning/blob/main/Assignment_03_part02%20-%20v1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xHJ-2a8LRro5"
      },
      "source": [
        "<img src=\"https://github.com/djp840/MSDS_458_Public/blob/master/images/NorthwesternHeader.png?raw=1\">"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k6cApW345ukg"
      },
      "source": [
        "## MSDS458 Research Assignment 3 - Part 02"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hblbilyx5ukg"
      },
      "source": [
        "## Analyze AG_NEWS_SUBSET Data <br>\n",
        "\n",
        "AG is a collection of more than 1 million news articles. News articles have been gathered from more than 2000 news sources by ComeToMyHead in more than 1 year of activity. ComeToMyHead is an academic news search engine which has been running since July, 2004. The dataset is provided by the academic comunity for research purposes in data mining (clustering, classification, etc), information retrieval (ranking, search, etc), xml, data compression, data streaming, and any other non-commercial activity.<br> \n",
        "\n",
        "For more information, please refer to the link http://www.di.unipi.it/~gulli/AG_corpus_of_news_articles.html<br> \n",
        "\n",
        "\n",
        "The AG's news topic classification dataset is constructed by choosing 4 largest classes (**World**, **Sports**, **Business**, and **Sci/Tech**) from the original corpus. Each class contains 30,000 training samples and 1,900 testing samples. The total number of training samples is 120,000 and testing 7,600.<br>\n",
        "\n",
        "Homepage: https://arxiv.org/abs/1509.01626<br>\n",
        "\n",
        "Source code: tfds.text.AGNewsSubset\n",
        "\n",
        "Versions:\n",
        "\n",
        "1.0.0 (default): No release notes.\n",
        "Download size: 11.24 MiB\n",
        "\n",
        "Dataset size: 35.79 MiB"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "95DGbFzR5uki"
      },
      "source": [
        "## References\n",
        "1. Deep Learning with Python, Francois Chollet (https://learning.oreilly.com/library/view/deep-learning-with/9781617296864/)\n",
        " * Chapter 10: Deep learning for time series\n",
        " * Chapter 11: Deep learning for text\n",
        "2. Deep Learning A Visual Approach, Andrew Glassner (https://learning.oreilly.com/library/view/deep-learning/9781098129019/)\n",
        " * Chapter 19: Recurrent Neural Networks\n",
        " * Chapter 20: Attention and Transformers"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vT8kwmgNRro7"
      },
      "source": [
        "## Processing words as a sequence: The sequence model approach\n",
        "\n",
        "To implement a sequence model, you’d start by representing your input samples as sequences of integer indices (one integer standing for one word). Then, you’d map each integer to a vector to obtain vector sequences. Finally, you’d feed these sequences of vectors into a stack of layers that could cross-correlate features from adjacent vectors, such as a 1D convnet, a RNN, or a Transformer."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x4AQ7tuV5ukj"
      },
      "source": [
        "For some time around 2016–2017, bidirectional RNNs (in particular, `bidirectional LSTMs`) were considered to be the state of the art for sequence modeling. However, nowadays sequence modeling is almost universally done with `Transformers`. \n",
        "\n",
        "F. Chollet: \"One-dimensional convnets were never very popular in NLP, even though, a residual stack of depthwise-separable 1D convolutions can often achieve comparable performance to a bidirectional LSTM, at a greatly reduced computational cost.\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ydgzc1l15ukl"
      },
      "source": [
        "## Import Packages"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "9d9VZa_T5ukm"
      },
      "outputs": [],
      "source": [
        "from packaging import version\n",
        "import numpy as np\n",
        "import re\n",
        "import string\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "import tensorflow_datasets as tfds\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "\n",
        "import nltk\n",
        "from nltk.corpus import stopwords"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SNt8VbLK5ukp"
      },
      "source": [
        "## Verify TensorFlow version and Keras version"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kujC9adr5ukq",
        "outputId": "7c2f3581-0e78-4d5d-e705-c7ea6839ae21"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "This notebook requires TensorFlow 2.0 or above\n",
            "TensorFlow version:  2.9.2\n"
          ]
        }
      ],
      "source": [
        "print(\"This notebook requires TensorFlow 2.0 or above\")\n",
        "print(\"TensorFlow version: \", tf.__version__)\n",
        "assert version.parse(tf.__version__).release[0] >=2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UHdPTZRp5ukr",
        "outputId": "13d7aced-df35-4610-8848-63d079f3c539"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Keras version:  2.9.0\n"
          ]
        }
      ],
      "source": [
        "print(\"Keras version: \", keras.__version__)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AHfRyGdPxref"
      },
      "source": [
        "## Stopword Function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "syHVsHBfxref"
      },
      "outputs": [],
      "source": [
        "def custom_stopwords(input_text):\n",
        "    lowercase = tf.strings.lower(input_text)\n",
        "    stripped_punct = tf.strings.regex_replace(lowercase\n",
        "                                  ,'[%s]' % re.escape(string.punctuation)\n",
        "                                  ,'')\n",
        "    return tf.strings.regex_replace(stripped_punct, r'\\b(' + r'|'.join(STOPWORDS) + r')\\b\\s*',\"\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z1Gn6wYG5uks"
      },
      "source": [
        "## Mount Google Drive to Colab environment"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "8jHzLMMB5ukt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7b3fec12-13dc-47aa-e3c5-940e42d00d60"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XvqFLia1Rro9"
      },
      "source": [
        "## Load Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EsypDzDARro-",
        "outputId": "3a2b33db-3378-40f4-ad34-f7e1209c13ce"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "W1029 22:06:16.109731 140198029043584 download_and_prepare.py:43] ***`tfds build` should be used instead of `download_and_prepare`.***\n",
            "INFO[build.py]: Loading dataset ag_news_subset from imports: tensorflow_datasets.text.ag_news_subset\n",
            "2022-10-29 22:06:16.457060: W tensorflow/core/platform/cloud/google_auth_provider.cc:184] All attempts to get a Google authentication bearer token failed, returning an empty token. Retrieving token from files failed with \"NOT_FOUND: Could not locate the credentials file.\". Retrieving token from GCE failed with \"NOT_FOUND: Error executing an HTTP request: HTTP response code 404\".\n",
            "INFO[dataset_info.py]: Load pre-computed DatasetInfo (eg: splits, num examples,...) from GCS: ag_news_subset/1.0.0\n",
            "INFO[dataset_info.py]: Load dataset info from /tmp/tmp6zflk0cqtfds\n",
            "INFO[dataset_info.py]: Field info.splits from disk and from code do not match. Keeping the one from code.\n",
            "INFO[dataset_info.py]: Field info.supervised_keys from disk and from code do not match. Keeping the one from code.\n",
            "INFO[dataset_info.py]: Field info.module_name from disk and from code do not match. Keeping the one from code.\n",
            "INFO[build.py]: download_and_prepare for dataset ag_news_subset/1.0.0...\n",
            "INFO[dataset_builder.py]: Generating dataset ag_news_subset (/root/tensorflow_datasets/ag_news_subset/1.0.0)\n",
            "\u001b[1mDownloading and preparing dataset 11.24 MiB (download: 11.24 MiB, generated: 35.79 MiB, total: 47.03 MiB) to /root/tensorflow_datasets/ag_news_subset/1.0.0...\u001b[0m\n",
            "Dl Completed...: 0 url [00:00, ? url/s]\n",
            "Dl Size...: 0 MiB [00:00, ? MiB/s]\u001b[A\n",
            "\n",
            "                                       \n",
            "\n",
            "\u001b[A\u001b[A\n",
            "\u001b[AINFO[download_manager.py]: Downloading https://drive.google.com/uc?export=download&id=0Bz8a_Dbh9QhbUDNpeUdjb0wxRms into /root/tensorflow_datasets/downloads/ucexport_download_id_0Bz8a_Dbh9QhbUDNpeUdjb0wxj4g1umFAV8OV-uDwxSJR0LdxO_k1jxMuFWwAfNX9jos.tmp.2de70475db4241afa4063f98c108fc8d...\n",
            "Dl Completed...: 0 url [00:00, ? url/s]\n",
            "\n",
            "Extraction completed...: 0 file [00:00, ? file/s]\u001b[A\u001b[A\n",
            "Dl Completed...:   0% 0/1 [00:00<?, ? url/s]\n",
            "Dl Size...: 0 MiB [00:00, ? MiB/s]\u001b[A\n",
            "\n",
            "Dl Completed...:   0% 0/1 [00:15<?, ? url/s]\n",
            "Dl Size...:   0% 0/11 [00:15<?, ? MiB/s]\u001b[A\n",
            "\n",
            "Extraction completed...: 0 file [00:15, ? file/s]\u001b[A\u001b[A\n",
            "Dl Completed...:   0% 0/1 [00:15<?, ? url/s]\n",
            "Dl Size...:   9% 1/11 [00:15<02:36, 15.63s/ MiB]\u001b[A\n",
            "\n",
            "Dl Completed...:   0% 0/1 [00:15<?, ? url/s]\n",
            "Dl Size...:  18% 2/11 [00:15<02:20, 15.63s/ MiB]\u001b[A\n",
            "\n",
            "Dl Completed...:   0% 0/1 [00:15<?, ? url/s]\n",
            "Dl Size...:  27% 3/11 [00:15<02:05, 15.63s/ MiB]\u001b[A\n",
            "\n",
            "Extraction completed...: 0 file [00:15, ? file/s]\u001b[A\u001b[A\n",
            "Dl Completed...:   0% 0/1 [00:16<?, ? url/s]\n",
            "Dl Size...:  36% 4/11 [00:16<00:21,  3.06s/ MiB]\u001b[A\n",
            "\n",
            "Dl Completed...:   0% 0/1 [00:16<?, ? url/s]\n",
            "Dl Size...:  45% 5/11 [00:16<00:18,  3.06s/ MiB]\u001b[A\n",
            "\n",
            "Dl Completed...:   0% 0/1 [00:16<?, ? url/s]\n",
            "Dl Size...:  55% 6/11 [00:16<00:15,  3.06s/ MiB]\u001b[A\n",
            "\n",
            "Dl Completed...:   0% 0/1 [00:16<?, ? url/s]\n",
            "Dl Size...:  64% 7/11 [00:16<00:12,  3.06s/ MiB]\u001b[A\n",
            "\n",
            "Dl Completed...:   0% 0/1 [00:16<?, ? url/s]\n",
            "Dl Size...:  73% 8/11 [00:16<00:09,  3.06s/ MiB]\u001b[A\n",
            "\n",
            "Dl Completed...:   0% 0/1 [00:16<?, ? url/s]\n",
            "Dl Size...:  82% 9/11 [00:16<00:06,  3.06s/ MiB]\u001b[A\n",
            "\n",
            "Dl Completed...:   0% 0/1 [00:16<?, ? url/s]\n",
            "Dl Size...:  91% 10/11 [00:16<00:03,  3.06s/ MiB]\u001b[A\n",
            "\n",
            "Dl Completed...:   0% 0/1 [00:16<?, ? url/s]\n",
            "Dl Size...: 100% 11/11 [00:16<00:00,  3.06s/ MiB]\u001b[A\n",
            "\n",
            "Dl Completed...: 100% 1/1 [00:16<00:00, 16.07s/ url]\n",
            "Dl Size...: 100% 11/11 [00:16<00:00,  3.06s/ MiB]\u001b[A\n",
            "\n",
            "Dl Completed...: 100% 1/1 [00:16<00:00, 16.07s/ url]\n",
            "Dl Size...: 100% 11/11 [00:16<00:00,  3.06s/ MiB]\u001b[A\n",
            "\n",
            "Extraction completed...:   0% 0/1 [00:16<?, ? file/s]\u001b[A\u001b[A\n",
            "\n",
            "Dl Completed...: 100% 1/1 [00:16<00:00, 16.07s/ url]\n",
            "Dl Size...: 100% 11/11 [00:16<00:00,  3.06s/ MiB]\u001b[A\n",
            "\n",
            "Extraction completed...: 100% 1/1 [00:16<00:00, 16.36s/ file]\n",
            "Dl Size...: 100% 11/11 [00:16<00:00,  1.49s/ MiB]\n",
            "Dl Completed...: 100% 1/1 [00:16<00:00, 16.36s/ url]\n",
            "Generating splits...:   0% 0/2 [00:00<?, ? splits/s]\n",
            "Generating train examples...:   0% 0/120000 [00:00<?, ? examples/s]\u001b[A\n",
            "Generating train examples...:   1% 979/120000 [00:00<00:12, 9785.74 examples/s]\u001b[A\n",
            "Generating train examples...:   2% 1958/120000 [00:00<00:12, 9476.53 examples/s]\u001b[A\n",
            "Generating train examples...:   2% 2907/120000 [00:00<00:12, 9262.15 examples/s]\u001b[A\n",
            "Generating train examples...:   3% 3957/120000 [00:00<00:11, 9737.77 examples/s]\u001b[A\n",
            "Generating train examples...:   4% 4976/120000 [00:00<00:11, 9897.93 examples/s]\u001b[A\n",
            "Generating train examples...:   5% 5976/120000 [00:00<00:11, 9932.06 examples/s]\u001b[A\n",
            "Generating train examples...:   6% 7010/120000 [00:00<00:11, 10063.12 examples/s]\u001b[A\n",
            "Generating train examples...:   7% 8064/120000 [00:00<00:10, 10212.36 examples/s]\u001b[A\n",
            "Generating train examples...:   8% 9086/120000 [00:00<00:11, 9890.89 examples/s] \u001b[A\n",
            "Generating train examples...:   8% 10155/120000 [00:01<00:10, 10128.67 examples/s]\u001b[A\n",
            "Generating train examples...:   9% 11177/120000 [00:01<00:10, 10155.22 examples/s]\u001b[A\n",
            "Generating train examples...:  10% 12195/120000 [00:01<00:10, 10029.42 examples/s]\u001b[A\n",
            "Generating train examples...:  11% 13200/120000 [00:01<00:10, 9896.15 examples/s] \u001b[A\n",
            "Generating train examples...:  12% 14254/120000 [00:01<00:10, 10083.25 examples/s]\u001b[A\n",
            "Generating train examples...:  13% 15273/120000 [00:01<00:10, 10111.46 examples/s]\u001b[A\n",
            "Generating train examples...:  14% 16286/120000 [00:01<00:10, 10029.89 examples/s]\u001b[A\n",
            "Generating train examples...:  14% 17337/120000 [00:01<00:10, 10170.93 examples/s]\u001b[A\n",
            "Generating train examples...:  15% 18355/120000 [00:01<00:10, 10148.88 examples/s]\u001b[A\n",
            "Generating train examples...:  16% 19389/120000 [00:01<00:09, 10205.48 examples/s]\u001b[A\n",
            "Generating train examples...:  17% 20416/120000 [00:02<00:09, 10222.79 examples/s]\u001b[A\n",
            "Generating train examples...:  18% 21439/120000 [00:02<00:09, 10175.26 examples/s]\u001b[A\n",
            "Generating train examples...:  19% 22491/120000 [00:02<00:09, 10276.08 examples/s]\u001b[A\n",
            "Generating train examples...:  20% 23519/120000 [00:02<00:09, 10022.66 examples/s]\u001b[A\n",
            "Generating train examples...:  20% 24523/120000 [00:02<00:09, 9891.01 examples/s] \u001b[A\n",
            "Generating train examples...:  21% 25535/120000 [00:02<00:09, 9955.49 examples/s]\u001b[A\n",
            "Generating train examples...:  22% 26565/120000 [00:02<00:09, 10056.18 examples/s]\u001b[A\n",
            "Generating train examples...:  23% 27572/120000 [00:02<00:09, 9856.29 examples/s] \u001b[A\n",
            "Generating train examples...:  24% 28565/120000 [00:02<00:09, 9876.96 examples/s]\u001b[A\n",
            "Generating train examples...:  25% 29583/120000 [00:02<00:09, 9964.93 examples/s]\u001b[A\n",
            "Generating train examples...:  25% 30581/120000 [00:03<00:09, 9789.76 examples/s]\u001b[A\n",
            "Generating train examples...:  26% 31609/120000 [00:03<00:08, 9931.84 examples/s]\u001b[A\n",
            "Generating train examples...:  27% 32646/120000 [00:03<00:08, 10058.52 examples/s]\u001b[A\n",
            "Generating train examples...:  28% 33653/120000 [00:03<00:08, 9756.50 examples/s] \u001b[A\n",
            "Generating train examples...:  29% 34634/120000 [00:03<00:08, 9771.49 examples/s]\u001b[A\n",
            "Generating train examples...:  30% 35663/120000 [00:03<00:08, 9920.47 examples/s]\u001b[A\n",
            "Generating train examples...:  31% 36684/120000 [00:03<00:08, 10004.16 examples/s]\u001b[A\n",
            "Generating train examples...:  31% 37743/120000 [00:03<00:08, 10176.50 examples/s]\u001b[A\n",
            "Generating train examples...:  32% 38762/120000 [00:03<00:08, 10121.92 examples/s]\u001b[A\n",
            "Generating train examples...:  33% 39775/120000 [00:03<00:08, 9731.62 examples/s] \u001b[A\n",
            "Generating train examples...:  34% 40752/120000 [00:04<00:08, 9720.86 examples/s]\u001b[A\n",
            "Generating train examples...:  35% 41770/120000 [00:04<00:07, 9854.72 examples/s]\u001b[A\n",
            "Generating train examples...:  36% 42785/120000 [00:04<00:07, 9938.33 examples/s]\u001b[A\n",
            "Generating train examples...:  36% 43781/120000 [00:04<00:07, 9761.01 examples/s]\u001b[A\n",
            "Generating train examples...:  37% 44759/120000 [00:04<00:07, 9528.75 examples/s]\u001b[A\n",
            "Generating train examples...:  38% 45723/120000 [00:04<00:07, 9560.37 examples/s]\u001b[A\n",
            "Generating train examples...:  39% 46765/120000 [00:04<00:07, 9810.01 examples/s]\u001b[A\n",
            "Generating train examples...:  40% 47824/120000 [00:04<00:07, 10039.06 examples/s]\u001b[A\n",
            "Generating train examples...:  41% 48830/120000 [00:04<00:07, 9937.10 examples/s] \u001b[A\n",
            "Generating train examples...:  42% 49871/120000 [00:05<00:06, 10074.91 examples/s]\u001b[A\n",
            "Generating train examples...:  42% 50924/120000 [00:05<00:06, 10208.23 examples/s]\u001b[A\n",
            "Generating train examples...:  43% 51946/120000 [00:05<00:06, 10119.34 examples/s]\u001b[A\n",
            "Generating train examples...:  44% 53006/120000 [00:05<00:06, 10260.06 examples/s]\u001b[A\n",
            "Generating train examples...:  45% 54033/120000 [00:05<00:06, 10077.16 examples/s]\u001b[A\n",
            "Generating train examples...:  46% 55042/120000 [00:05<00:06, 9997.88 examples/s] \u001b[A\n",
            "Generating train examples...:  47% 56043/120000 [00:05<00:06, 9951.99 examples/s]\u001b[A\n",
            "Generating train examples...:  48% 57097/120000 [00:05<00:06, 10124.67 examples/s]\u001b[A\n",
            "Generating train examples...:  48% 58111/120000 [00:05<00:06, 10087.26 examples/s]\u001b[A\n",
            "Generating train examples...:  49% 59121/120000 [00:05<00:06, 10073.60 examples/s]\u001b[A\n",
            "Generating train examples...:  50% 60180/120000 [00:06<00:05, 10226.63 examples/s]\u001b[A\n",
            "Generating train examples...:  51% 61204/120000 [00:06<00:05, 10058.57 examples/s]\u001b[A\n",
            "Generating train examples...:  52% 62238/120000 [00:06<00:05, 10138.95 examples/s]\u001b[A\n",
            "Generating train examples...:  53% 63256/120000 [00:06<00:05, 10150.40 examples/s]\u001b[A\n",
            "Generating train examples...:  54% 64272/120000 [00:06<00:05, 9851.15 examples/s] \u001b[A\n",
            "Generating train examples...:  54% 65287/120000 [00:06<00:05, 9937.07 examples/s]\u001b[A\n",
            "Generating train examples...:  55% 66318/120000 [00:06<00:05, 10045.09 examples/s]\u001b[A\n",
            "Generating train examples...:  56% 67324/120000 [00:06<00:05, 9973.56 examples/s] \u001b[A\n",
            "Generating train examples...:  57% 68366/120000 [00:06<00:05, 10104.35 examples/s]\u001b[A\n",
            "Generating train examples...:  58% 69411/120000 [00:06<00:04, 10204.46 examples/s]\u001b[A\n",
            "Generating train examples...:  59% 70433/120000 [00:07<00:04, 10039.45 examples/s]\u001b[A\n",
            "Generating train examples...:  60% 71472/120000 [00:07<00:04, 10142.70 examples/s]\u001b[A\n",
            "Generating train examples...:  60% 72509/120000 [00:07<00:04, 10207.70 examples/s]\u001b[A\n",
            "Generating train examples...:  61% 73531/120000 [00:07<00:04, 10161.40 examples/s]\u001b[A\n",
            "Generating train examples...:  62% 74548/120000 [00:07<00:04, 9795.01 examples/s] \u001b[A\n",
            "Generating train examples...:  63% 75531/120000 [00:07<00:04, 9635.72 examples/s]\u001b[A\n",
            "Generating train examples...:  64% 76497/120000 [00:07<00:04, 9508.20 examples/s]\u001b[A\n",
            "Generating train examples...:  65% 77450/120000 [00:07<00:04, 9288.65 examples/s]\u001b[A\n",
            "Generating train examples...:  65% 78453/120000 [00:07<00:04, 9499.46 examples/s]\u001b[A\n",
            "Generating train examples...:  66% 79456/120000 [00:07<00:04, 9653.78 examples/s]\u001b[A\n",
            "Generating train examples...:  67% 80428/120000 [00:08<00:04, 9671.72 examples/s]\u001b[A\n",
            "Generating train examples...:  68% 81409/120000 [00:08<00:03, 9709.86 examples/s]\u001b[A\n",
            "Generating train examples...:  69% 82420/120000 [00:08<00:03, 9826.08 examples/s]\u001b[A\n",
            "Generating train examples...:  70% 83409/120000 [00:08<00:03, 9842.70 examples/s]\u001b[A\n",
            "Generating train examples...:  70% 84394/120000 [00:08<00:03, 9660.61 examples/s]\u001b[A\n",
            "Generating train examples...:  71% 85390/120000 [00:08<00:03, 9747.95 examples/s]\u001b[A\n",
            "Generating train examples...:  72% 86403/120000 [00:08<00:03, 9858.05 examples/s]\u001b[A\n",
            "Generating train examples...:  73% 87409/120000 [00:08<00:03, 9916.96 examples/s]\u001b[A\n",
            "Generating train examples...:  74% 88402/120000 [00:08<00:03, 9830.19 examples/s]\u001b[A\n",
            "Generating train examples...:  75% 89413/120000 [00:08<00:03, 9912.49 examples/s]\u001b[A\n",
            "Generating train examples...:  75% 90449/120000 [00:09<00:02, 10043.30 examples/s]\u001b[A\n",
            "Generating train examples...:  76% 91466/120000 [00:09<00:02, 10080.09 examples/s]\u001b[A\n",
            "Generating train examples...:  77% 92475/120000 [00:09<00:02, 10071.88 examples/s]\u001b[A\n",
            "Generating train examples...:  78% 93523/120000 [00:09<00:02, 10191.62 examples/s]\u001b[A\n",
            "Generating train examples...:  79% 94543/120000 [00:09<00:02, 9822.34 examples/s] \u001b[A\n",
            "Generating train examples...:  80% 95570/120000 [00:09<00:02, 9952.38 examples/s]\u001b[A\n",
            "Generating train examples...:  80% 96584/120000 [00:09<00:02, 10005.83 examples/s]\u001b[A\n",
            "Generating train examples...:  81% 97587/120000 [00:09<00:02, 10005.82 examples/s]\u001b[A\n",
            "Generating train examples...:  82% 98634/120000 [00:09<00:02, 10143.32 examples/s]\u001b[A\n",
            "Generating train examples...:  83% 99656/120000 [00:10<00:02, 10160.95 examples/s]\u001b[A\n",
            "Generating train examples...:  84% 100676/120000 [00:10<00:01, 10169.83 examples/s]\u001b[A\n",
            "Generating train examples...:  85% 101737/120000 [00:10<00:01, 10300.15 examples/s]\u001b[A\n",
            "Generating train examples...:  86% 102768/120000 [00:10<00:01, 10234.95 examples/s]\u001b[A\n",
            "Generating train examples...:  86% 103792/120000 [00:10<00:01, 10162.53 examples/s]\u001b[A\n",
            "Generating train examples...:  87% 104809/120000 [00:10<00:01, 9509.12 examples/s] \u001b[A\n",
            "Generating train examples...:  88% 105826/120000 [00:10<00:01, 9696.63 examples/s]\u001b[A\n",
            "Generating train examples...:  89% 106843/120000 [00:10<00:01, 9832.47 examples/s]\u001b[A\n",
            "Generating train examples...:  90% 107832/120000 [00:10<00:01, 9507.90 examples/s]\u001b[A\n",
            "Generating train examples...:  91% 108789/120000 [00:10<00:01, 9474.28 examples/s]\u001b[A\n",
            "Generating train examples...:  92% 109833/120000 [00:11<00:01, 9753.63 examples/s]\u001b[A\n",
            "Generating train examples...:  92% 110846/120000 [00:11<00:00, 9863.26 examples/s]\u001b[A\n",
            "Generating train examples...:  93% 111859/120000 [00:11<00:00, 9939.86 examples/s]\u001b[A\n",
            "Generating train examples...:  94% 112925/120000 [00:11<00:00, 10152.52 examples/s]\u001b[A\n",
            "Generating train examples...:  95% 113942/120000 [00:11<00:00, 10130.60 examples/s]\u001b[A\n",
            "Generating train examples...:  96% 114957/120000 [00:11<00:00, 9836.68 examples/s] \u001b[A\n",
            "Generating train examples...:  97% 115986/120000 [00:11<00:00, 9968.81 examples/s]\u001b[A\n",
            "Generating train examples...:  98% 117015/120000 [00:11<00:00, 10062.70 examples/s]\u001b[A\n",
            "Generating train examples...:  98% 118023/120000 [00:11<00:00, 10040.18 examples/s]\u001b[A\n",
            "Generating train examples...:  99% 119029/120000 [00:12<00:00, 8091.93 examples/s] \u001b[A\n",
            "Generating train examples...: 100% 119899/120000 [00:12<00:00, 7058.15 examples/s]\u001b[A\n",
            "                                                                                  \u001b[A\n",
            "Shuffling /root/tensorflow_datasets/ag_news_subset/1.0.0.incompleteT1KLGX/ag_news_subset-train.tfrecord*...:   0% 0/120000 [00:00<?, ? examples/s]\u001b[A\n",
            "Shuffling /root/tensorflow_datasets/ag_news_subset/1.0.0.incompleteT1KLGX/ag_news_subset-train.tfrecord*...:   0% 1/120000 [00:00<6:39:27,  5.01 examples/s]\u001b[A\n",
            "Shuffling /root/tensorflow_datasets/ag_news_subset/1.0.0.incompleteT1KLGX/ag_news_subset-train.tfrecord*...:  20% 24159/120000 [00:00<00:00, 100737.78 examples/s]\u001b[A\n",
            "Shuffling /root/tensorflow_datasets/ag_news_subset/1.0.0.incompleteT1KLGX/ag_news_subset-train.tfrecord*...:  40% 48597/120000 [00:00<00:00, 154356.41 examples/s]\u001b[A\n",
            "Shuffling /root/tensorflow_datasets/ag_news_subset/1.0.0.incompleteT1KLGX/ag_news_subset-train.tfrecord*...:  67% 80440/120000 [00:00<00:00, 211416.33 examples/s]\u001b[A\n",
            "Shuffling /root/tensorflow_datasets/ag_news_subset/1.0.0.incompleteT1KLGX/ag_news_subset-train.tfrecord*...:  88% 105963/120000 [00:00<00:00, 225953.28 examples/s]\u001b[A\n",
            "INFO[writer.py]: Done writing /root/tensorflow_datasets/ag_news_subset/1.0.0.incompleteT1KLGX/ag_news_subset-train.tfrecord*. Number of examples: 120000 (shards: [120000])\n",
            "Generating splits...:  50% 1/2 [00:12<00:12, 12.94s/ splits]\n",
            "Generating test examples...:   0% 0/7600 [00:00<?, ? examples/s]\u001b[A\n",
            "Generating test examples...:   6% 420/7600 [00:00<00:01, 4197.98 examples/s]\u001b[A\n",
            "Generating test examples...:  12% 888/7600 [00:00<00:01, 4480.14 examples/s]\u001b[A\n",
            "Generating test examples...:  19% 1416/7600 [00:00<00:01, 4841.79 examples/s]\u001b[A\n",
            "Generating test examples...:  25% 1913/7600 [00:00<00:01, 4890.01 examples/s]\u001b[A\n",
            "Generating test examples...:  32% 2402/7600 [00:00<00:01, 4878.83 examples/s]\u001b[A\n",
            "Generating test examples...:  38% 2920/7600 [00:00<00:00, 4979.64 examples/s]\u001b[A\n",
            "Generating test examples...:  45% 3418/7600 [00:00<00:00, 4695.81 examples/s]\u001b[A\n",
            "Generating test examples...:  51% 3891/7600 [00:00<00:00, 4635.41 examples/s]\u001b[A\n",
            "Generating test examples...:  58% 4404/7600 [00:00<00:00, 4783.65 examples/s]\u001b[A\n",
            "Generating test examples...:  65% 4927/7600 [00:01<00:00, 4916.51 examples/s]\u001b[A\n",
            "Generating test examples...:  72% 5439/7600 [00:01<00:00, 4976.25 examples/s]\u001b[A\n",
            "Generating test examples...:  79% 5986/7600 [00:01<00:00, 5121.93 examples/s]\u001b[A\n",
            "Generating test examples...:  86% 6500/7600 [00:01<00:00, 4487.43 examples/s]\u001b[A\n",
            "Generating test examples...:  92% 6996/7600 [00:01<00:00, 4615.99 examples/s]\u001b[A\n",
            "Generating test examples...:  99% 7503/7600 [00:01<00:00, 4741.75 examples/s]\u001b[A\n",
            "                                                                             \u001b[A\n",
            "Shuffling /root/tensorflow_datasets/ag_news_subset/1.0.0.incompleteT1KLGX/ag_news_subset-test.tfrecord*...:   0% 0/7600 [00:00<?, ? examples/s]\u001b[A\n",
            "INFO[writer.py]: Done writing /root/tensorflow_datasets/ag_news_subset/1.0.0.incompleteT1KLGX/ag_news_subset-test.tfrecord*. Number of examples: 7600 (shards: [7600])\n",
            "\u001b[1mDataset ag_news_subset downloaded and prepared to /root/tensorflow_datasets/ag_news_subset/1.0.0. Subsequent calls will reuse this data.\u001b[0m\n",
            "INFO[build.py]: Dataset generation complete...\n",
            "\n",
            "tfds.core.DatasetInfo(\n",
            "    name='ag_news_subset',\n",
            "    full_name='ag_news_subset/1.0.0',\n",
            "    description=\"\"\"\n",
            "    AG is a collection of more than 1 million news articles.\n",
            "    News articles have been gathered from more than 2000  news sources by ComeToMyHead in more than 1 year of activity.\n",
            "    ComeToMyHead is an academic news search engine which has been running since July, 2004.\n",
            "    The dataset is provided by the academic comunity for research purposes in data mining (clustering, classification, etc),\n",
            "    information retrieval (ranking, search, etc), xml, data compression, data streaming,\n",
            "    and any other non-commercial activity.\n",
            "    For more information, please refer to the link http://www.di.unipi.it/~gulli/AG_corpus_of_news_articles.html .\n",
            "    \n",
            "    The AG's news topic classification dataset is constructed by Xiang Zhang (xiang.zhang@nyu.edu) from the dataset above.\n",
            "    It is used as a text classification benchmark in the following paper:\n",
            "    Xiang Zhang, Junbo Zhao, Yann LeCun. Character-level Convolutional Networks for Text Classification. Advances in Neural Information Processing Systems 28 (NIPS 2015).\n",
            "    \n",
            "    The AG's news topic classification dataset is constructed by choosing 4 largest classes from the original corpus.\n",
            "    Each class contains 30,000 training samples and 1,900 testing samples.\n",
            "    The total number of training samples is 120,000 and testing 7,600.\n",
            "    \"\"\",\n",
            "    homepage='https://arxiv.org/abs/1509.01626',\n",
            "    data_path='/root/tensorflow_datasets/ag_news_subset/1.0.0',\n",
            "    file_format=tfrecord,\n",
            "    download_size=11.24 MiB,\n",
            "    dataset_size=35.79 MiB,\n",
            "    features=FeaturesDict({\n",
            "        'description': Text(shape=(), dtype=tf.string),\n",
            "        'label': ClassLabel(shape=(), dtype=tf.int64, num_classes=4),\n",
            "        'title': Text(shape=(), dtype=tf.string),\n",
            "    }),\n",
            "    supervised_keys=('description', 'label'),\n",
            "    disable_shuffling=False,\n",
            "    splits={\n",
            "        'test': <SplitInfo num_examples=7600, num_shards=1>,\n",
            "        'train': <SplitInfo num_examples=120000, num_shards=1>,\n",
            "    },\n",
            "    citation=\"\"\"@misc{zhang2015characterlevel,\n",
            "        title={Character-level Convolutional Networks for Text Classification},\n",
            "        author={Xiang Zhang and Junbo Zhao and Yann LeCun},\n",
            "        year={2015},\n",
            "        eprint={1509.01626},\n",
            "        archivePrefix={arXiv},\n",
            "        primaryClass={cs.LG}\n",
            "    }\"\"\",\n",
            ")\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# register  ag_news_subset so that tfds.load doesn't generate a checksum (mismatch) error\n",
        "!python -m tensorflow_datasets.scripts.download_and_prepare --register_checksums --datasets=ag_news_subset\n",
        "\n",
        "dataset,info=\\\n",
        "tfds.load('ag_news_subset', with_info=True,  split=['train[:95%]','train[95%:]', 'test'],batch_size = 32\n",
        "          , as_supervised=True)\n",
        "\n",
        "train_ds, val_ds, test_ds = dataset\n",
        "text_only_train_ds = train_ds.map(lambda x, y: x)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mq7Q6zlFRro_"
      },
      "source": [
        "## Preparing Integer Sequence Datasets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XzuiyImJxreh",
        "outputId": "3292146c-f9a1-4d8f-d6c4-fe03e260b082"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        }
      ],
      "source": [
        "nltk.download('stopwords')\n",
        "STOPWORDS = stopwords.words(\"english\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "AfTnCGIERrpA"
      },
      "outputs": [],
      "source": [
        "max_length = 150\n",
        "max_tokens = 1000\n",
        "text_vectorization = layers.TextVectorization(\n",
        "    max_tokens=max_tokens,\n",
        "    output_mode=\"int\",\n",
        "    output_sequence_length=max_length,\n",
        "    standardize=custom_stopwords\n",
        ")\n",
        "text_vectorization.adapt(text_only_train_ds)\n",
        "\n",
        "int_train_ds = train_ds.map(\n",
        "    lambda x, y: (text_vectorization(x), y),\n",
        "    num_parallel_calls=4)\n",
        "int_val_ds = val_ds.map(\n",
        "    lambda x, y: (text_vectorization(x), y),\n",
        "    num_parallel_calls=4)\n",
        "int_test_ds = test_ds.map(\n",
        "    lambda x, y: (text_vectorization(x), y),\n",
        "    num_parallel_calls=4)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NBL0CkaB5ukv"
      },
      "source": [
        "## Bi-directional RNN\n",
        "\n",
        "When translating in real-time, it would help to have access to worlds towards the end of a sentence, say, as well as earlier words in the sentence. One way to use the later words in the sentence is to feed the words into our RNN backward. So if we create two independent RNNs, we can feed one the words in their forward, or natural order, and the second gets their words in the revser order. This is the idea behind `Bi-directional RNNS`:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EuP7exeZ5ukw"
      },
      "source": [
        "<img src=\"https://github.com/djp840/MSDS_458_Public/blob/master/images/BidirectionalRNN.png?raw=1\">"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FCNo3kUl5ukw"
      },
      "source": [
        "<img src=\"https://github.com/djp840/MSDS_458_Public/blob/master/images/Bidirectional2RNN.png?raw=1\">"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qN2wjSjdRrpB"
      },
      "source": [
        "## Sequence Model Built on One-Hot Encoded Vector Sequences"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Hq6dB-zWRrpB",
        "outputId": "3341cee5-8830-4a17-df9b-432780c79131"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_1 (InputLayer)        [(None, None)]            0         \n",
            "                                                                 \n",
            " tf.one_hot (TFOpLambda)     (None, None, 1000)        0         \n",
            "                                                                 \n",
            " bidirectional (Bidirectiona  (None, 64)               264448    \n",
            " l)                                                              \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 64)                0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 4)                 260       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 264,708\n",
            "Trainable params: 264,708\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "inputs = tf.keras.Input(shape=(None,), dtype=\"int64\")\n",
        "embedded = tf.one_hot(inputs, depth=max_tokens)\n",
        "x = layers.Bidirectional(layers.LSTM(32))(embedded)\n",
        "x = layers.Dropout(0.5)(x)\n",
        "outputs = layers.Dense(4, activation=\"softmax\")(x)\n",
        "model = tf.keras.Model(inputs, outputs)\n",
        "model.compile(optimizer=\"rmsprop\",\n",
        "              loss=\"SparseCategoricalCrossentropy\",\n",
        "              metrics=[\"accuracy\"])\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R64NWZQc5ukx"
      },
      "source": [
        "## One input is a sequence of integers.\n",
        "\n",
        "1. In order to keep a manageable input size, we’ll truncate the inputs after the first 150 words. This is a reasonable choice, since the average review length is 233 words, and only 5% of reviews are longer than 150 words.\n",
        "\n",
        "2. Encode the integers into binary 1,000-dimensional vectors.\n",
        "\n",
        "3. Add a bidirectional LSTM.\n",
        "\n",
        "4. Finally, add a classification layer."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ognTeJM6RrpC"
      },
      "source": [
        "## Training Sequence Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5kCbHrrsRrpC",
        "outputId": "c4a08c8e-3493-4935-e67d-3296b1735dc5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/200\n",
            "3563/3563 [==============================] - 69s 17ms/step - loss: 0.5652 - accuracy: 0.8016 - val_loss: 0.4162 - val_accuracy: 0.8562\n",
            "Epoch 2/200\n",
            "3563/3563 [==============================] - 58s 16ms/step - loss: 0.4371 - accuracy: 0.8505 - val_loss: 0.4025 - val_accuracy: 0.8598\n",
            "Epoch 3/200\n",
            "3563/3563 [==============================] - 60s 17ms/step - loss: 0.4235 - accuracy: 0.8551 - val_loss: 0.4013 - val_accuracy: 0.8585\n",
            "Epoch 4/200\n",
            "3563/3563 [==============================] - 58s 16ms/step - loss: 0.4139 - accuracy: 0.8577 - val_loss: 0.3987 - val_accuracy: 0.8597\n",
            "Epoch 5/200\n",
            "3563/3563 [==============================] - 59s 17ms/step - loss: 0.4077 - accuracy: 0.8600 - val_loss: 0.3980 - val_accuracy: 0.8588\n",
            "238/238 [==============================] - 3s 10ms/step - loss: 0.4074 - accuracy: 0.8572\n",
            "Test acc: 0.857\n"
          ]
        }
      ],
      "source": [
        "callbacks = [\n",
        "    tf.keras.callbacks.ModelCheckpoint(\"one_hot_bidir_lstm.keras\",\n",
        "                                    save_best_only=True)\n",
        "    ,tf.keras.callbacks.EarlyStopping(monitor='val_accuracy', patience=3)\n",
        "]\n",
        "model.fit(int_train_ds, validation_data=int_val_ds, epochs=200, callbacks=callbacks)\n",
        "model = keras.models.load_model(\"one_hot_bidir_lstm.keras\")\n",
        "print(f\"Test acc: {model.evaluate(int_test_ds)[1]:.3f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fTprEi3bRrpD"
      },
      "source": [
        "## Understanding word embeddings"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pmHdhUnM5ukz"
      },
      "source": [
        "When you encode something via `one-hot encoding`, you’re making a feature-engineering decision. You’re injecting into your model a fundamental assumption about the structure of your feature space. That assumption is that the different tokens you’re encoding are all independent from each other: indeed, one-hot vectors are all orthogonal to one another."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "webaWkZJ5ukz"
      },
      "source": [
        "However, in a reasonable word vector space, you would expect synonyms to be embedded into similar word vectors, and in general, you would expect the geometric distance  between any two word vectors to relate to the “semantic distance” between the associated words.\n",
        "\n",
        "Words that mean different things should lie far away from each other, whereas related words should be closer."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b-W1sFgg5ukz"
      },
      "source": [
        "`Word embeddings` are vector representations of words that achieve exactly this: they map human language into a structured geometric space."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0egzHasW5ukz"
      },
      "source": [
        "Whereas the vectors obtained through `one-hot encoding` are *binary*, *sparse*, and *very high-dimensional* (the same dimensionality as the number of words in the vocabulary), `word embeddings` are *low-dimensional floating-point vectors* (that is, `dense vectors`, as opposed to `sparse vectors`)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dHU4tS3b5uk0"
      },
      "source": [
        "<img src=\"https://github.com/djp840/MSDS_458_Public/blob/master/images/EmbeddingsSparse.png?raw=1\">"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "im1j5PRE5uk0"
      },
      "source": [
        "## Two ways to obtain word embeddings\n",
        "\n",
        "1. `Learn word embeddings jointly with the main task you care about` (such as document classification or sentiment prediction). In this setup, you start with random word vectors and then learn word vectors in the same way you learn the weights of a neural network.\n",
        "2. Load into your model word embeddings that were precomputed using a different machine learning task than the one you’re trying to solve. These are called `pretrained word embeddings`.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0CNyH_fhRrpD"
      },
      "source": [
        "## Learning Word Embeddings With The Embedding Layer"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LsYLfdJY5uk0"
      },
      "source": [
        "What makes a good word-embedding space depends heavily on your task: the perfect word-embedding space for an English-language movie-review sentiment-analysis model may look different from the perfect embedding space for an English-language legal-document classification model, because the importance of certain semantic relationships varies from task to task.\n",
        "\n",
        "It’s thus reasonable to learn a new embedding space with every new task."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j69C96c65uk1"
      },
      "source": [
        "<div class=\"alert alert-block alert-success\"><b>tf.keras.layers.Embedding</b><br>\n",
        "https://www.tensorflow.org/api_docs/python/tf/keras/layers/Embedding </div>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NrVeqKcsRrpE"
      },
      "source": [
        "## Instantiating An Embedding Layer\n",
        "\n",
        "The Embedding layer takes at least two arguments: the number of possible tokens and the dimensionality of the embeddings (here, 256)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "WLTjxbMnRrpE"
      },
      "outputs": [],
      "source": [
        "embedding_layer = layers.Embedding(input_dim=max_tokens, output_dim=256)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vWx26f9C5uk2"
      },
      "source": [
        "The Embedding layer is best understood as a dictionary that maps integer indices (which stand for specific words) to dense vectors"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7Mox7FQp5uk2"
      },
      "source": [
        "The Embedding layer takes as input a rank-2 tensor of integers, of shape `(batch_size, sequence_length)`, where each entry is a sequence of integers. The layer then returns a 3D floating-point tensor of shape `(batch_size, sequence_length, embedding_ dimensionality)`.Again, embedding_ dimensionality is 256 above."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PSfWWNO6RrpE"
      },
      "source": [
        "## Model Leveraging Trained Embedding Layer"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FLuGKCM35uk2"
      },
      "source": [
        "One input is a sequence of integers.\n",
        "1. Encode the integers into binary 20,000-dimensional vectors.\n",
        "2. Add a bidirectional LSTM.\n",
        "3. Finally, add a classification layer."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O6JFON-CRrpF",
        "outputId": "250fee44-a31e-46ac-ee8f-4d6dd87dd32d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_2 (InputLayer)        [(None, None)]            0         \n",
            "                                                                 \n",
            " embedding_1 (Embedding)     (None, None, 256)         256000    \n",
            "                                                                 \n",
            " bidirectional_1 (Bidirectio  (None, 64)               73984     \n",
            " nal)                                                            \n",
            "                                                                 \n",
            " dropout_1 (Dropout)         (None, 64)                0         \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 4)                 260       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 330,244\n",
            "Trainable params: 330,244\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/200\n",
            "3563/3563 [==============================] - 62s 17ms/step - loss: 0.5000 - accuracy: 0.8276 - val_loss: 0.4117 - val_accuracy: 0.8580\n",
            "Epoch 2/200\n",
            "3563/3563 [==============================] - 60s 17ms/step - loss: 0.4308 - accuracy: 0.8525 - val_loss: 0.4001 - val_accuracy: 0.8577\n",
            "Epoch 3/200\n",
            "3563/3563 [==============================] - 58s 16ms/step - loss: 0.4151 - accuracy: 0.8568 - val_loss: 0.3892 - val_accuracy: 0.8615\n",
            "Epoch 4/200\n",
            "3563/3563 [==============================] - 59s 17ms/step - loss: 0.4057 - accuracy: 0.8600 - val_loss: 0.3874 - val_accuracy: 0.8628\n",
            "Epoch 5/200\n",
            "3563/3563 [==============================] - 58s 16ms/step - loss: 0.3958 - accuracy: 0.8620 - val_loss: 0.3819 - val_accuracy: 0.8635\n",
            "Epoch 6/200\n",
            "3563/3563 [==============================] - 59s 17ms/step - loss: 0.3893 - accuracy: 0.8643 - val_loss: 0.3831 - val_accuracy: 0.8657\n",
            "Epoch 7/200\n",
            "3563/3563 [==============================] - 58s 16ms/step - loss: 0.3833 - accuracy: 0.8668 - val_loss: 0.3866 - val_accuracy: 0.8670\n",
            "Epoch 8/200\n",
            "3563/3563 [==============================] - 58s 16ms/step - loss: 0.3790 - accuracy: 0.8687 - val_loss: 0.3844 - val_accuracy: 0.8660\n",
            "Epoch 9/200\n",
            "3563/3563 [==============================] - 59s 17ms/step - loss: 0.3731 - accuracy: 0.8703 - val_loss: 0.3822 - val_accuracy: 0.8682\n",
            "Epoch 10/200\n",
            "3563/3563 [==============================] - 58s 16ms/step - loss: 0.3671 - accuracy: 0.8732 - val_loss: 0.3854 - val_accuracy: 0.8683\n",
            "Epoch 11/200\n",
            "3563/3563 [==============================] - 59s 17ms/step - loss: 0.3644 - accuracy: 0.8739 - val_loss: 0.3828 - val_accuracy: 0.8677\n",
            "Epoch 12/200\n",
            "3563/3563 [==============================] - 58s 16ms/step - loss: 0.3572 - accuracy: 0.8759 - val_loss: 0.3848 - val_accuracy: 0.8687\n",
            "Epoch 13/200\n",
            "3563/3563 [==============================] - 59s 17ms/step - loss: 0.3542 - accuracy: 0.8776 - val_loss: 0.3899 - val_accuracy: 0.8687\n",
            "Epoch 14/200\n",
            "3563/3563 [==============================] - 57s 16ms/step - loss: 0.3493 - accuracy: 0.8797 - val_loss: 0.3937 - val_accuracy: 0.8645\n",
            "Epoch 15/200\n",
            "3563/3563 [==============================] - 59s 16ms/step - loss: 0.3448 - accuracy: 0.8812 - val_loss: 0.3914 - val_accuracy: 0.8680\n",
            "238/238 [==============================] - 3s 8ms/step - loss: 0.3917 - accuracy: 0.8654\n",
            "Test acc: 0.865\n"
          ]
        }
      ],
      "source": [
        "inputs = tf.keras.Input(shape=(None,), dtype=\"int64\")\n",
        "embedded = layers.Embedding(input_dim=max_tokens, output_dim=256)(inputs)\n",
        "x = layers.Bidirectional(layers.LSTM(32))(embedded)\n",
        "x = layers.Dropout(0.5)(x)\n",
        "outputs = layers.Dense(4, activation=\"softmax\")(x)\n",
        "model = tf.keras.Model(inputs, outputs)\n",
        "model.compile(optimizer=\"rmsprop\",\n",
        "              loss=\"SparseCategoricalCrossentropy\",\n",
        "              metrics=[\"accuracy\"])\n",
        "model.summary()\n",
        "\n",
        "callbacks = [\n",
        "    tf.keras.callbacks.ModelCheckpoint(\"embeddings_bidir_gru.keras\",\n",
        "                                    save_best_only=True)\n",
        "    ,tf.keras.callbacks.EarlyStopping(monitor='val_accuracy', patience=3)\n",
        "]\n",
        "model.fit(int_train_ds, validation_data=int_val_ds, epochs=200, callbacks=callbacks)\n",
        "model = keras.models.load_model(\"embeddings_bidir_gru.keras\")\n",
        "print(f\"Test acc: {model.evaluate(int_test_ds)[1]:.3f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HHF_wA3x5uk3"
      },
      "source": [
        "It trains much faster than the one-hot model (since the LSTM only has to process 256-dimensional vectors instead of 1,000-dimensional), and its test accuracy is comparable (86%)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M0gOTdNnRrpF"
      },
      "source": [
        "## Understanding Padding and Masking"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zOudeXoa5uk4"
      },
      "source": [
        "One thing that’s slightly hurting model performance here is that our input sequences are full of zeros. This comes from our use of the `output_sequence_length=max_ length` option in TextVectorization (with `max_length equal` to 150): sentences longer than 150 tokens are truncated to a length of 150 tokens, and sentences shorter than 150 tokens are padded with zeros at the end so that they can be concatenated together with other sequences to form contiguous batches."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hM95tdc65uk4"
      },
      "source": [
        "The RNN that looks at the tokens in their natural order will spend its last iterations seeing only vectors that encode padding—possibly for several hundreds of iterations if the original sentence was short. The information stored in the internal state of the RNN will gradually fade out as it gets exposed to these meaningless inputs."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U93_Szgn5uk4"
      },
      "source": [
        "We need some way to tell the RNN that it should skip these iterations. There’s an API for that: `masking`."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t1SxQSW85uk4"
      },
      "source": [
        "<div class=\"alert alert-block alert-success\"><b>tf.keras.layers.Masking</b><br>\n",
        "https://www.tensorflow.org/api_docs/python/tf/keras/layers/Masking</div>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HGe0pvoxRrpF"
      },
      "source": [
        "## Model Leveraging Embedding Layer With Masking Enabled"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tU6YKNrDRrpF",
        "outputId": "f78fbbec-31ba-4ec7-d579-9fc7b7964e28"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_2\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_3 (InputLayer)        [(None, None)]            0         \n",
            "                                                                 \n",
            " embedding_2 (Embedding)     (None, None, 256)         256000    \n",
            "                                                                 \n",
            " bidirectional_2 (Bidirectio  (None, 64)               73984     \n",
            " nal)                                                            \n",
            "                                                                 \n",
            " dropout_2 (Dropout)         (None, 64)                0         \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 4)                 260       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 330,244\n",
            "Trainable params: 330,244\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/200\n",
            "3563/3563 [==============================] - 64s 16ms/step - loss: 0.4746 - accuracy: 0.8332 - val_loss: 0.4023 - val_accuracy: 0.8590\n",
            "Epoch 2/200\n",
            "3563/3563 [==============================] - 55s 16ms/step - loss: 0.4138 - accuracy: 0.8541 - val_loss: 0.3881 - val_accuracy: 0.8615\n",
            "Epoch 3/200\n",
            "3563/3563 [==============================] - 56s 16ms/step - loss: 0.3995 - accuracy: 0.8587 - val_loss: 0.3842 - val_accuracy: 0.8615\n",
            "Epoch 4/200\n",
            "3563/3563 [==============================] - 55s 15ms/step - loss: 0.3893 - accuracy: 0.8638 - val_loss: 0.3820 - val_accuracy: 0.8635\n",
            "Epoch 5/200\n",
            "3563/3563 [==============================] - 57s 16ms/step - loss: 0.3802 - accuracy: 0.8667 - val_loss: 0.3808 - val_accuracy: 0.8647\n",
            "Epoch 6/200\n",
            "3563/3563 [==============================] - 55s 15ms/step - loss: 0.3734 - accuracy: 0.8697 - val_loss: 0.3797 - val_accuracy: 0.8670\n",
            "Epoch 7/200\n",
            "3563/3563 [==============================] - 56s 16ms/step - loss: 0.3659 - accuracy: 0.8723 - val_loss: 0.3795 - val_accuracy: 0.8645\n",
            "Epoch 8/200\n",
            "3563/3563 [==============================] - 55s 15ms/step - loss: 0.3584 - accuracy: 0.8752 - val_loss: 0.3812 - val_accuracy: 0.8668\n",
            "Epoch 9/200\n",
            "3563/3563 [==============================] - 56s 16ms/step - loss: 0.3522 - accuracy: 0.8771 - val_loss: 0.3825 - val_accuracy: 0.8693\n",
            "Epoch 10/200\n",
            "3563/3563 [==============================] - 55s 15ms/step - loss: 0.3442 - accuracy: 0.8805 - val_loss: 0.3825 - val_accuracy: 0.8668\n",
            "Epoch 11/200\n",
            "3563/3563 [==============================] - 56s 16ms/step - loss: 0.3379 - accuracy: 0.8826 - val_loss: 0.3838 - val_accuracy: 0.8652\n",
            "Epoch 12/200\n",
            "3563/3563 [==============================] - 55s 15ms/step - loss: 0.3320 - accuracy: 0.8851 - val_loss: 0.3893 - val_accuracy: 0.8663\n",
            "238/238 [==============================] - 4s 6ms/step - loss: 0.3945 - accuracy: 0.8626\n",
            "Test acc: 0.863\n"
          ]
        }
      ],
      "source": [
        "inputs = tf.keras.Input(shape=(None,), dtype=\"int64\")\n",
        "embedded = layers.Embedding(\n",
        "    input_dim=max_tokens, output_dim=256, mask_zero=True)(inputs)\n",
        "x = layers.Bidirectional(layers.LSTM(32))(embedded)\n",
        "x = layers.Dropout(0.5)(x)\n",
        "outputs = layers.Dense(4, activation=\"softmax\")(x)\n",
        "model = tf.keras.Model(inputs, outputs)\n",
        "model.compile(optimizer=\"rmsprop\",\n",
        "              loss=\"SparseCategoricalCrossentropy\",\n",
        "              metrics=[\"accuracy\"])\n",
        "model.summary()\n",
        "\n",
        "callbacks = [\n",
        "    tf.keras.callbacks.ModelCheckpoint(\"embeddings_bidir_gru_with_masking.keras\",\n",
        "                                    save_best_only=True)\n",
        "    ,tf.keras.callbacks.EarlyStopping(monitor='val_accuracy', patience=3)\n",
        "]\n",
        "model.fit(int_train_ds, validation_data=int_val_ds, epochs=200, callbacks=callbacks)\n",
        "model = keras.models.load_model(\"embeddings_bidir_gru_with_masking.keras\")\n",
        "print(f\"Test acc: {model.evaluate(int_test_ds)[1]:.3f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SDRunHYSRrpG"
      },
      "source": [
        "## Using Pretrained Word Embeddings"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ivO55Vo15uk6"
      },
      "source": [
        "The rationale behind using `pretrained word embedding`s in natural language processing is much the same as for using pretrained convnets in image classification: *you don’t have enough data available to learn truly powerful features on your own*, but you expect that the features you need are fairly generic—that is, common visual features or semantic features. In this case, it makes sense to reuse features learned on a different problem."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XllLQfXb5uk6"
      },
      "source": [
        "The idea of a dense, low-dimensional embedding space for words, computed in an unsupervised way, was initially explored by Bengio et al. in the early 2000s, but it only started to take off in research and industry applications after the release of one of the most famous and successful word-embedding schemes: the `Word2Vec` algorithm (https://code.google.com/archive/p/word2vec), developed by Tomas Mikolov at Google in 2013. `Word2Vec` dimensions capture specific semantic properties, such as gender."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "riqJwrpr5uk6"
      },
      "source": [
        "There are various precomputed databases of word embeddings that you can download and use in a Keras Embedding layer. `Word2vec` is one of them. Another popular one is called `Global Vectors for Word Representatio`n (GloVe, https://nlp.stanford.edu/projects/glove), which was developed by Stanford researchers in 2014. This embedding technique is based on factorizing a matrix of word co-occurrence statistics. Its developers have made available precomputed embeddings for millions of English tokens, obtained from Wikipedia data and Common Crawl data."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oKNrxDE65uk6"
      },
      "source": [
        "First, let’s download the GloVe word embeddings precomputed on the 2014 English Wikipedia dataset. It’s an 822 MB zip file containing 100-dimensional embedding vectors for 400,000 words (or non-word tokens)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5P6O5iXN5uk7"
      },
      "source": [
        "<div class=\"alert alert-block alert-success\"><b>GloVe: Global Vectors for Word Representation</b><br>\n",
        "https://nlp.stanford.edu/projects/glove/</div>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-EjBZq6cRrpG",
        "outputId": "09e49d27-7199-4c45-c364-9558de628137"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2022-10-29 22:46:22--  http://nlp.stanford.edu/data/glove.6B.zip\n",
            "Resolving nlp.stanford.edu (nlp.stanford.edu)... 171.64.67.140\n",
            "Connecting to nlp.stanford.edu (nlp.stanford.edu)|171.64.67.140|:80... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://nlp.stanford.edu/data/glove.6B.zip [following]\n",
            "--2022-10-29 22:46:22--  https://nlp.stanford.edu/data/glove.6B.zip\n",
            "Connecting to nlp.stanford.edu (nlp.stanford.edu)|171.64.67.140|:443... connected.\n",
            "HTTP request sent, awaiting response... 301 Moved Permanently\n",
            "Location: https://downloads.cs.stanford.edu/nlp/data/glove.6B.zip [following]\n",
            "--2022-10-29 22:46:23--  https://downloads.cs.stanford.edu/nlp/data/glove.6B.zip\n",
            "Resolving downloads.cs.stanford.edu (downloads.cs.stanford.edu)... 171.64.64.22\n",
            "Connecting to downloads.cs.stanford.edu (downloads.cs.stanford.edu)|171.64.64.22|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 862182613 (822M) [application/zip]\n",
            "Saving to: ‘glove.6B.zip’\n",
            "\n",
            "glove.6B.zip        100%[===================>] 822.24M  3.48MB/s    in 4m 51s  \n",
            "\n",
            "2022-10-29 22:51:16 (2.83 MB/s) - ‘glove.6B.zip’ saved [862182613/862182613]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!wget http://nlp.stanford.edu/data/glove.6B.zip\n",
        "!unzip -q glove.6B.zip"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o4Ifl-sJRrpH"
      },
      "source": [
        "## Parsing The GloVe Word-Embeddings File\n",
        "\n",
        "First line of `glove.6B.100d.txt`:\n",
        "\n",
        "`the -0.038194 -0.24487 0.72812 ...`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VPo9aWdbRrpH",
        "outputId": "265a737a-bd6e-409e-b474-88714c0f0966"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 400000 word vectors.\n"
          ]
        }
      ],
      "source": [
        "path_to_glove_file = \"glove.6B.100d.txt\"\n",
        "\n",
        "embeddings_index = {}\n",
        "with open(path_to_glove_file) as f:\n",
        "    for line in f:\n",
        "        word, coefs = line.split(maxsplit=1)\n",
        "        coefs = np.fromstring(coefs, \"f\", sep=\" \") # np.dtype('f') returns dtype('float32')\n",
        "        embeddings_index[word] = coefs\n",
        "\n",
        "print(f\"Found {len(embeddings_index)} word vectors.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "evKxdRndRrpH"
      },
      "source": [
        "## Preparing The GloVe Word-Embeddings Matrix\n",
        "\n",
        "Next, let’s build an embedding matrix that you can load into an Embedding layer. It must be a matrix of shape `(max_words, embedding_dim)`, where each entry *i* contains the `embedding_dim`-dimensional vector for the word of index *i* in the reference word index (built during tokenization)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "jSCD2_KcRrpI"
      },
      "outputs": [],
      "source": [
        "embedding_dim = 100\n",
        "\n",
        "# Retrieve the vocabulary indexed by our previous TextVectorization layer.\n",
        "vocabulary = text_vectorization.get_vocabulary()\n",
        "\n",
        "# Use it to create a mapping from words to their index in the vocabulary.\n",
        "word_index = dict(zip(vocabulary, range(len(vocabulary))))\n",
        "\n",
        "# Prepare a matrix that we’ll fill with the GloVe vectors.\n",
        "embedding_matrix = np.zeros((max_tokens, embedding_dim))\n",
        "\n",
        "# Fill entry i in the matrix with the word vector for index i.\n",
        "for word, i in word_index.items():\n",
        "    if i < max_tokens:\n",
        "        embedding_vector = embeddings_index.get(word)\n",
        "    if embedding_vector is not None:  # Words not found in the embedding index will be all zeros.\n",
        "        embedding_matrix[i] = embedding_vector"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "ZE2xRs4QRrpI"
      },
      "outputs": [],
      "source": [
        "embedding_layer = layers.Embedding(\n",
        "    max_tokens,\n",
        "    embedding_dim,\n",
        "    embeddings_initializer=keras.initializers.Constant(embedding_matrix),\n",
        "    trainable=False,\n",
        "    mask_zero=True,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PUsE9u-g5uk9"
      },
      "source": [
        "We’re now ready to train a new model—identical to our previous model, but leveraging the `100-dimensional` pretrained GloVe embeddings instead of `256-dimensional` learned embeddings."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2aXYeW8o5uk9"
      },
      "source": [
        "## One possible alternative to GloVE: ELMo (Embedding from Language Models)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bOckichs5uk9"
      },
      "source": [
        "<img src=\"https://github.com/djp840/MSDS_458_Public/blob/master/images/ELMoArchitecture.png?raw=1\">"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NeEWdhm_5uk9"
      },
      "source": [
        "### \"Although the word is written in the identical way in each sentence, ELMo is able to identify the correct embedding based on the word’s context.\"\n",
        "\n",
        "<img src=\"https://github.com/djp840/MSDS_458_Public/blob/master/images/ELMoComparison.png?raw=1\">\n",
        "\n",
        "https://colab.research.google.com/github/tensorflow/hub/blob/master/examples/colab/semantic_similarity_with_tf_hub_universal_encoder.ipynb#scrollTo=cPMCaxrZwp7t"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VOA_ss3iRrpJ"
      },
      "source": [
        "## Model Leveraging Pretrained (GloVe) Embedding Layer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RI8Tj4g1RrpJ",
        "outputId": "7e26f4e1-b685-4f96-be8c-5ac434810016",
        "scrolled": false
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_3\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_4 (InputLayer)        [(None, None)]            0         \n",
            "                                                                 \n",
            " embedding_3 (Embedding)     (None, None, 100)         100000    \n",
            "                                                                 \n",
            " bidirectional_3 (Bidirectio  (None, 64)               34048     \n",
            " nal)                                                            \n",
            "                                                                 \n",
            " dropout_3 (Dropout)         (None, 64)                0         \n",
            "                                                                 \n",
            " dense_3 (Dense)             (None, 4)                 260       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 134,308\n",
            "Trainable params: 34,308\n",
            "Non-trainable params: 100,000\n",
            "_________________________________________________________________\n",
            "Epoch 1/200\n",
            "3563/3563 [==============================] - 59s 14ms/step - loss: 0.4825 - accuracy: 0.8285 - val_loss: 0.4086 - val_accuracy: 0.8503\n",
            "Epoch 2/200\n",
            "3563/3563 [==============================] - 50s 14ms/step - loss: 0.4252 - accuracy: 0.8467 - val_loss: 0.3938 - val_accuracy: 0.8553\n",
            "Epoch 3/200\n",
            "3563/3563 [==============================] - 50s 14ms/step - loss: 0.4061 - accuracy: 0.8541 - val_loss: 0.3851 - val_accuracy: 0.8612\n",
            "Epoch 4/200\n",
            "3563/3563 [==============================] - 52s 14ms/step - loss: 0.3947 - accuracy: 0.8583 - val_loss: 0.3802 - val_accuracy: 0.8592\n",
            "Epoch 5/200\n",
            "3563/3563 [==============================] - 52s 15ms/step - loss: 0.3856 - accuracy: 0.8618 - val_loss: 0.3772 - val_accuracy: 0.8620\n",
            "Epoch 6/200\n",
            "3563/3563 [==============================] - 52s 15ms/step - loss: 0.3776 - accuracy: 0.8637 - val_loss: 0.3735 - val_accuracy: 0.8643\n",
            "Epoch 7/200\n",
            "3563/3563 [==============================] - 50s 14ms/step - loss: 0.3720 - accuracy: 0.8660 - val_loss: 0.3731 - val_accuracy: 0.8628\n",
            "Epoch 8/200\n",
            "3563/3563 [==============================] - 49s 14ms/step - loss: 0.3666 - accuracy: 0.8680 - val_loss: 0.3743 - val_accuracy: 0.8653\n",
            "Epoch 9/200\n",
            "3563/3563 [==============================] - 49s 14ms/step - loss: 0.3606 - accuracy: 0.8699 - val_loss: 0.3729 - val_accuracy: 0.8670\n",
            "Epoch 10/200\n",
            "3563/3563 [==============================] - 51s 14ms/step - loss: 0.3560 - accuracy: 0.8726 - val_loss: 0.3753 - val_accuracy: 0.8665\n",
            "Epoch 11/200\n",
            "3563/3563 [==============================] - 50s 14ms/step - loss: 0.3501 - accuracy: 0.8746 - val_loss: 0.3796 - val_accuracy: 0.8678\n",
            "Epoch 12/200\n",
            "3563/3563 [==============================] - 51s 14ms/step - loss: 0.3456 - accuracy: 0.8762 - val_loss: 0.3772 - val_accuracy: 0.8678\n",
            "Epoch 13/200\n",
            "3563/3563 [==============================] - 50s 14ms/step - loss: 0.3416 - accuracy: 0.8778 - val_loss: 0.3867 - val_accuracy: 0.8653\n",
            "Epoch 14/200\n",
            "3563/3563 [==============================] - 51s 14ms/step - loss: 0.3396 - accuracy: 0.8784 - val_loss: 0.3812 - val_accuracy: 0.8650\n",
            "238/238 [==============================] - 4s 6ms/step - loss: 0.3906 - accuracy: 0.8632\n",
            "Test acc: 0.863\n"
          ]
        }
      ],
      "source": [
        "inputs = tf.keras.Input(shape=(None,), dtype=\"int64\")\n",
        "embedded = embedding_layer(inputs)\n",
        "x = layers.Bidirectional(layers.LSTM(32))(embedded)\n",
        "x = layers.Dropout(0.5)(x)\n",
        "outputs = layers.Dense(4, activation=\"softmax\")(x)\n",
        "model = tf.keras.Model(inputs, outputs)\n",
        "model.compile(optimizer=\"rmsprop\",\n",
        "              loss=\"SparseCategoricalCrossentropy\",\n",
        "              metrics=[\"accuracy\"])\n",
        "model.summary()\n",
        "\n",
        "callbacks = [\n",
        "    tf.keras.callbacks.ModelCheckpoint(\"glove_embeddings_sequence_model.keras\",\n",
        "                                    save_best_only=True)\n",
        "    ,tf.keras.callbacks.EarlyStopping(monitor='val_accuracy', patience=3)\n",
        "]\n",
        "model.fit(int_train_ds, validation_data=int_val_ds, epochs=200, callbacks=callbacks)\n",
        "model = keras.models.load_model(\"glove_embeddings_sequence_model.keras\")\n",
        "print(f\"Test acc: {model.evaluate(int_test_ds)[1]:.3f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "5fqFXCOO5uk-"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "machine_shape": "hm",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
